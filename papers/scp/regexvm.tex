\documentclass[review]{elsarticle}

\usepackage{xcolor}
\usepackage{
  coqdoc
}

\usepackage{lineno,hyperref}
\modulolinenumbers[5]
\usepackage{graphicx,hyperref}
\usepackage{float}
\usepackage{proof,tikz,minted}
\usepackage{amssymb,amsthm,stmaryrd}


\usetikzlibrary{automata}
\usetikzlibrary{shapes}
\usetikzlibrary{backgrounds}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}


\journal{Science of Computer Programming}

%%%%%%%%%%%%%%%%%%%%%%%
%% Elsevier bibliography styles
%%%%%%%%%%%%%%%%%%%%%%%
%% To change the style, put a % in front of the second line of the current style and
%% remove the % from the second line of the style you would like to use.
%%%%%%%%%%%%%%%%%%%%%%%

%% Numbered
%\bibliographystyle{model1-num-names}

%% Numbered without titles
%\bibliographystyle{model1a-num-names}

%% Harvard
%\bibliographystyle{model2-names.bst}\biboptions{authoryear}

%% Vancouver numbered
%\usepackage{numcompress}\bibliographystyle{model3-num-names}

%% Vancouver name/year
%\usepackage{numcompress}\bibliographystyle{model4-names}\biboptions{authoryear}

%% APA style
%\bibliographystyle{model5-names}\biboptions{authoryear}

%% AMA style
%\usepackage{numcompress}\bibliographystyle{model6-num-names}

%% `Elsevier LaTeX' style
\bibliographystyle{elsarticle-num}
%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\Eps}{\textit{Eps}}
\newcommand{\Chr}{\textit{Chr}}
\newcommand{\Catt}{\textit{Cat}}
\newcommand{\Left}{\textit{Left}}
\newcommand{\Right}{\textit{Right}}
\newcommand{\StarBase}{\textit{StarBase}}
\newcommand{\StarRec}{\textit{StarRec}}
\newcommand{\sembrackets}[1]{\ensuremath{\llbracket #1 \rrbracket}}
\newcommand{\flatten}{\ensuremath{\texttt{flatten}}}
\newcommand{\inl}{\ensuremath{\texttt{inl}}}
\newcommand{\inr}{\ensuremath{\texttt{inr}}}
\newcommand{\code}{\ensuremath{\texttt{encode}}}
\newcommand{\decodee}{\ensuremath{\texttt{decode}}}
\newcommand{\decodeo}{\ensuremath{\texttt{decode1}}}
\newcommand{\leti}{\ensuremath{\textbf{\texttt{let}}}}
\newcommand{\iin}{\ensuremath{\textbf{\texttt{in}}}}
\newcommand{\iif}{\ensuremath{\textbf{\texttt{if}}}}
\newcommand{\tthen}{\ensuremath{\textbf{\texttt{then}}}}
\newcommand{\eelse}{\ensuremath{\textbf{\texttt{else}}}}
\newcommand{\eerror}{\ensuremath{\textbf{\texttt{error}}}}
\newcommand{\nullable}{\ensuremath{\texttt{nullable}}}
\newcommand{\emptyy}{\ensuremath{\texttt{empty}}}
\newcommand{\fin}{\ensuremath{\texttt{f$_{\texttt{in}}$}}}
\newcommand{\fout}{\ensuremath{\texttt{f$_{\texttt{out}}$}}}
\newcommand{\size}{\ensuremath{\texttt{size}}}

\newcommand{\coq}[1]{\mintinline{coq}|#1|}
\newcommand{\haskell}[1]{\mintinline{haskell}|#1|}

\theoremstyle{definition}

\newtheorem{Theorem}{Theorem}
\newtheorem*{Theorem*}{Theorem}
\newtheorem{Example}{Example}
\newtheorem{Lemma}{Lemma}

\begin{document}

\begin{frontmatter}

\title{Certified Virtual Machine Based Regular Expression Parsing}

%% Group authors per affiliation:
\author{Elton Cardoso}
\address{Departamento de Computa\c{c}\~ao e Sistemas - DECSI, Universidade Federal de Ouro Preto}
\author{Thales Delfino}
\author{Rodrigo Ribeiro}
\address{Programa de P\'os-Gradua\c{c}\~ao em Ci\^encia da Computa\c{c}\~ao -
  PPGCC, Universidade Federal de Ouro Preto}
\author{Andr\'e Rauber Du Bois}
\address{Programa de P\'os-Gradua\c{c}\~ao em Computa\c{c}\~ao -
  PPGC, Universidade Federal de Pelotas}
\author{Leonardo Reis}
\address{Departamento de Computa\c{c}\~ao, Universidade Federal de Juiz de Fora}


\begin{abstract}
Regular expressions (REs) are pervasive in computing. We use REs in text editors, string search tools
(like GNU-Grep) and lexical analysers generators. Most of these tools rely on
converting REs to their corresponding finite state machines or use REs derivatives for directly parse an
input string. In this work, we investigate the suitability of another approach: instead of
using derivatives or generating a finite state machine for a given RE, we developed a virtual machine
(VM) for parsing regular languages, in such a way that a RE is merely a program executed by the VM
over the input string. We show that the proposed semantics is sound w.r.t. a standard
inductive semantics for RE and that the evidence produced by it denotes a valid parsing result.
All of our results are formalized in Coq proof assistant and from it we extract a certified algorithm
which we use to build a RE parsing tool using Haskell programming language. Experiments comparing the
efficiency of our algorithm with other approaches implemented using Haskell are reported.
\end{abstract}

\begin{keyword}
Regular Expressions, Virtual Machines, Parsing
\end{keyword}

\end{frontmatter}

\linenumbers

%\input{paper}

\section{Introduction}\label{sec:intro}

We name parsing the process of analyzing if a sequence of symbols matches a given set of rules.
Such rules are usually specified in a formal notation, like a grammar. If a string can be obtained
from those rules, we have success: we can build some evidence that the input is in the language
described by the underlying formalism. Otherwise, we have a failure: no such evidence exists.

In this work, we focus on the parsing problem for regular expressions (REs), which are an algebraic
and compact way of defining regular languages (RLs), i.e., languages that can be recognized by
(non-)deterministic finite automata and equivalent formalisms. REs are widely used in string search
tools, lexical analyser generators and XML schema languages~\cite{Frisch2004}. Since RE parsing
is pervasive in computing, its correctness is crucial. Nowadays, with the recent
development of languages with dependent types and proof assistants it has become
possible to represent algorithmic properties as program types which are verified
by the compiler. The usage of proof assistants to verify RE parsing / matching algorithms
were the subject of study of several recent research works (e.g ~\cite{Firsov13,Ribeiro2017,Lopes2016,Asperti10}).

Approaches for RE parsing can use representations of finite state machines (e.g.~\cite{Firsov13}),
derivatives (e.g.~\cite{Ribeiro2017,Lopes2018,Lopes2016}) or the so-called pointed RE's or its
variants~\cite{Asperti10,Fischer2010}. Another approach for parsing is based on the so-called
parsing machines, which dates back to 70's with Knuth's work
on top-down syntax analysis for context-free languages~\cite{Knuth71}. Recently, some works
have tried to revive the use of such machines for parsing: Cox~\cite{Cox2009} defined a VM
for which a RE can be seen as ``high-level programs'' that can be compiled to a sequence of
such VM instructions and Lua library LPEG~\cite{Ierusalimschy2009} defines a VM whose instruction
set can be used to compile Parser Expressions Grammars (PEGs)~\cite{Ford04}. Such renewed research
interest is motivated by the fact that is possible to include new features by just adding and
implementing new machine instructions.

Cox's work on VM-based RE parsing has problems. First, it is poorly specified: both the VM semantics 
and the RE compilation process are described only informally and no correctness guarantee is even mentioned. 
Second, it does not provide an evidence for matching, which could be used to characterize a disambiguation 
strategy, like Greedy~\cite{Frisch2004} and POSIX~\cite{Sulzmann14}. To the best of our knowledge, no 
previous work has formally defined a VM for RE parsing that produces evidence (parse trees) for successful matches.
The objective of this work is to give a first step in filling this gap. More specifically, we are interested in formally
specify and prove the correctness of a VM based semantics for RE parsing which produces bit-codes as
a memory efficient representation of parse-trees. As pointed by~\cite{Lasse2011}, bit-codes are useful because they
are not only smaller than the parse tree, but also smaller than the string being parsed and they can be combined with methods
for text compression. We would like to emphasize that, unlike Cox's work, which develops its VM using a instruction 
set like syntax and semantics, we use, as inspiration, virtual machines for the~$\lambda$-calculus, like the 
SECD and Krivine machines~\cite{Krivine07,Landin64}. 

One important issue regarding RE parsing is how to deal with the so-called problematic 
RE\footnote{We say that a RE $e$ is problematic if there's exists $e_1$ s.t. $e = e_1^\star$ and 
$e_1$ accepts the empty string.}\cite{Frisch2004}. In order to avoid the well-known issues with 
problematic RE, we use a transformation proposed by Medeiros et. al.~\cite{Medeiros14} which turns a
problematic RE into an equivalent non-problematic one. We prove that this algorithm indeed produce
equivalent REs using Coq proof assistant.

Our contributions are:

\begin{itemize}
  \item We present a big step semantics for a greedy RE parsing VM which produces bit-codes as parsing evidence.
  \item We develop a certified implementation of an algorithm that converts a problematic RE into a 
  non-problematic one.
  \item We prove that the bit-codes produced by our VM are valid parsing evidence.
  \item We extract from our formalization a certified algorithm in Haskell and use it 
  to build a RE parsing tool. We compare its performance against 
  well known Haskell library for RE parsing.  
\end{itemize}

This paper describes the continuation of the RE VM-based parsing research which we previously reported 
on a paper published on SBLP 2018~\cite{Delfino18}. The current work improves our previous results
mainly by: 1) using a big-step operational semantics which deals correctly with problematic REs, unlike
our previous small-step semantics. We simply transform problematic REs into
equivalent non-problematic ones before starting their execution by our semantics;
2) we proved that the proposed semantics is deterministic by following the
greedy disambiguation strategy; 3) all results of this paper are completely mechanized using Coq
proof assistant. Our previous work used property-based testing in order to provide an evidence for 
the correctness of the small-step semantics.    

The rest of this paper is organized as follows.
Section~\ref{section:background} presents some 
background concepts on RE and its parsing problem. 
Our operational semantics for RE parsing and its theoretical properties
are described in Section~\ref{section:semantics}. Our Coq formalization is described in 
Section~\ref{section:formalization}.  Section~\ref{section:experiments} presents some experimental
results regarding the tool produced using the verified algorithm and Section~\ref{section:related} discuss
related works. Finally, Section~\ref{section:conclusion} concludes and 
presents some directions for future work.

While all the code on which this paper is based has been developed in Coq,
we adopt a ``lighter'' syntax when presenting its code fragments. 
We chose this presentation style in order to improve readability, because
 functions that use dependently typed pattern matching require a high number of type
 annotations, which would deviate from our objective of providing an easily
 understandable formalization. A brief introduction to Coq proof assistant can be
 found on~\ref{section:coq} and proof sketchs of the main paper results
 are presented on~\ref{section:proofs-scketchs}.

\paragraph{Coq formalization} All source code produced, including the source of this article, 
instructions on how to build it and replicate the reported experiments are avaliable 
on-line~\cite{regexvm-rep}.

\section{Background}\label{section:background}


\subsection{Regular expressions: syntax and semantics}\label{subsection:resyntaxsemantics}


REs are defined with respect to a given alphabet. Formally, the following context-free
grammar defines RE syntax:

\[
e ::= \emptyset\,\mid\,\epsilon\,\mid\,a\,\mid\,e\,e\,\mid\,e+e\,\mid\,e^{\star}
\]

Meta-variable $e$ will denote an arbitrary RE and $a$ an
arbitrary alphabet symbol. As usual, all meta-variables can appear primed or subscripted.
In our Coq formalization, we represent alphabet symbols using type \coq{ascii}. We let concatenation
of RE, strings and lists by juxtaposition. Notation $|s|$
denotes the size of an string $s$. Given a RE, we let its \size~ be defined by the following 
function:


\[
\begin{array}{lcl}
   \size(\emptyset) & = & 0 \\
   \size(\epsilon)  & = & 1 \\
   \size(a)         & = & 2 \\
   \size(e_1 + e_2) & = & 1 + \size(e_1) + \size(e_2)\\
   \size(e_1\,e_2)  & = & 1 + \size(e_1) + \size(e_2)\\
   \size(e ^\star)  & = & 1 + \size(e)
\end{array}
\]

Given a pair $(e,s)$, formed by a RE expression $e$ and a string $s$, we define its complexity as
$(\size(e),|s|)$. 

Following common practice \cite{Lopes2016,Ribeiro2017,Rathnayake2011}, we adopt an inductive
characterization of RE membership semantics. We let judgment $s \in \sembrackets{e}$ denote
that string $s$ is in the language denoted by RE $e$ (Figure~\ref{figure:resemantics}).

\begin{figure}[h]
	\[
	\begin{array}{cc}
	\infer[_{\{\Eps\}}]
	{\epsilon \in \sembrackets{\epsilon}}{} &
	\infer[_{\{\Chr\}}]
	{a \in \sembrackets{a}}{a \in \Sigma} \\ \\
	\infer[_{\{\Left\}}]
	{s \in \sembrackets{e + e'}}{s \in \sembrackets{e}} &
	\infer[_{\{\Right\}}]
	{s' \in \sembrackets{e + e'}}{s' \in \sembrackets{e'}} \\ \\
	\infer[_{\{\StarBase\}}]
	{\epsilon \in \sembrackets{e^\star}}{} &
	\infer[_{\{\StarRec\}}]
	{ss' \in \sembrackets{e^\star}}
	{s \in \sembrackets{e} & s' \in \sembrackets{e^\star}} \\ \\
	\multicolumn{2}{c}{
		\infer[_{\{\Catt\}}]
		{ss' \in \sembrackets{ee'}}
		{s \in \sembrackets{e} & s' \in \sembrackets{e'}}
	} \\
	\end{array}
	\]
	\centering
	\caption{RE inductive semantics.}
	\label{figure:resemantics}
\end{figure}

Rule $\Eps$ states that the empty string (denoted by the $\epsilon$)
is in the language of RE $\epsilon$. For any single character $a$, the singleton
string \coq{a} is in the language 
of RE $a$. Given membership proofs for REs $e$ and $e'$, $s \in \sembrackets{e}$ 
and $s' \in\sembrackets{e'}$, rule $\Catt$ can be used to build a proof
for the concatenation of these REs.  Rule \Left~(\Right) creates a membership proof
for $e + e'$ from a proof for $e$ ($e'$). Semantics for Kleene star
is built using the following well known equivalence of REs: $e^\star
= \epsilon + e\,e^\star$. 

We say that two REs are equivalent, written $e\approx e'$, if the following holds:

\[
\forall s. s\in \Sigma^\star \to s \in\sembrackets{e} \leftrightarrow s\in\sembrackets{e'} 
\]


\subsection{RE parsing and bit-coded parse trees}\label{subsection:bitcodedparsetrees}

One way to represent parsing evidence is to build a tree that denotes
a RE membership proof. Following Frisch et. al. and Nielsen et.
al.~\cite{Lasse2011,Frisch2004},
we let parse trees be terms whose type is its underlying RE. The following context-free 
grammar defines the syntax of parse trees, where we use a Haskell-like syntax for 
lists.

\begin{figure}[h]
   \[
      \begin{array}{lcl}
         t & \to & () \,\mid\, a \,\mid\, \texttt{inl}\:t  \,\mid\, \texttt{inr}\:t  \,\mid\, \langle t,\,t\rangle  \,\mid\, [\,]\,\mid\,t : ts
      \end{array}
   \]
   \caption{Parse trees for REs.}
   \label{figure:parsetreesyntax}
\end{figure}

Term $()$ denotes the parse tree for $\epsilon$ and $a$ the tree for a single character RE. 
Constructor \texttt{inl} (\texttt{inr}) tags parse trees for the left (right) operand in 
a union RE. A parse tree for the concatenation $e\:e'$ is a pair formed by a tree for $e$ and 
another for $e'$. A parse tree for $e^\star$ is a list of trees for RE $e$. Such relationship 
between trees and REs is formalized by typing judgment $\vdash t : e$, which specifies that 
$t$ is a parse tree for the RE $e$. The typing judgment is defined in Figure~\ref{figure:parsetreetyping}.


\begin{figure}[h]
   \[ 
       \begin{array}{ccc}
         \infer{\vdash () : \epsilon}{} & \hspace{.5cm} & \infer{\vdash a : a}{}\\
         \\
         \infer{\vdash \texttt{inl }t : e + e'}{\vdash t : e}  & & 
         \infer{\vdash \texttt{inr }t : e + e'}{\vdash t : e'} \\ 
         \\
         \infer{\vdash \langle t_1, t_2 \rangle : e_1\:e_2}
               {\vdash t_1 : e_1 & \vdash t_2 : e_2}   & & 
         \infer{\vdash [\,] : e^\star}{} \\ \\
         \multicolumn{3}{c}{
           \infer{\vdash t : ts : e ^\star}
                 {\vdash t : e & \vdash ts : e ^\star}
         }
       \end{array}
   \]
   \caption{Parse tree typing relation.}
   \label{figure:parsetreetyping}
\end{figure}


For any parse tree $t$, we can produce its parsed string using function 
\flatten, which is defined below:
\begin{figure}[h]
\[
\begin{array}{lcl}
   \flatten\,() & = & \epsilon\\
   \flatten\,a  & = & a \\
   \flatten\,(\inl\:t) & = & \flatten\:t\\
   \flatten\,(\inr\:t) & = & \flatten\:t\\
   \flatten\,\langle t_1, t_2 \rangle & = & (\flatten\,t_1)(\flatten\,t_2)\\
   \flatten\,[\,] & = & \epsilon\\
   \flatten\,(t:ts) & = & (\flatten\,t)(\flatten\,ts)
\end{array}
\]
\caption{Function for parse tree flattening.}
\label{figure:flatten}
\end{figure}

\begin{Example}
\label{example:parsetree}
Consider the RE $((ab)+c)^*$ and the string $abcab$, which is accepted by that RE. 
Here is shown the string's corresponding parse tree:

\begin{center}
\begin{tikzpicture}[tlabel/.style={font=\footnotesize}]
\node{$[\,]$}
   child{
     node{inl}
     child{
       node {$\langle,\rangle$}
       child{node{a}}
       child{node{b}}
     }
   }
   child{
     node{inr}
     child{node {c}}
   }
   child{
     node{inl}
     child{
       node {$\langle,\rangle$}
       child{node{a}}
       child{node{b}}
     }
};
\end{tikzpicture}
\end{center}

\end{Example}

The next theorems relates parse trees and RE semantics.
The first one can be proved by an easy induction on the RE semantics derivation 
and the second by induction on the derivation of $\vdash t : e$.

\begin{Theorem}\label{theorem:semanticstypingflatten}
   For all $s$ and $e$, if $s \in \sembrackets{e}$ then exists a tree $t$
   such that \texttt{flatten } $t$ = $s$ and $\vdash t : e$.
\end{Theorem}
% \begin{proof}
%   Induction on the derivation of $s \in \sembrackets{e}$.
% \end{proof}

\begin{Theorem}\label{theorem:typingflattensemantics}
If $\vdash t : e$ then (\texttt{flatten }t)$\in\sembrackets{e}$. 
\end{Theorem}
% \begin{proof}
%    Induction on the derivation of $\vdash t : e$.
% \end{proof}

Nielsen et. al.~\cite{Lasse2011} proposed the
use of bit-marks to register which branch was chosen in a parse tree for union
operator, $+$, and to delimit different matches done by Kleene star expression.
Evidently, not all bit sequences correspond to valid parse trees. Ribeiro et. al.~\cite{Ribeiro2017}
showed an inductively defined relation between valid bit-codes and RE, accordingly to the encoding
proposed by~\cite{Lasse2011}. We let the judgement $bs \rhd e$ denote that the sequence of bits
$bs$ corresponds to a parse-tree for RE $e$. The bit-code typing relation is
presented as an inductively defined judgement in Figure~\ref{figure:typing-bitcodes}.

\begin{figure}[h]
	\[
	\begin{array}{ccc}
	\infer{[\,] \rhd \epsilon}{} &
	\infer{[\,] \rhd a}{}  &
	\infer{0_b\, bs \rhd e + e'}{bs \rhd e} \\ \\
	\infer{1_b\,bs \rhd e + e'}{bs \rhd e'} &
	\infer{bs\,bs' \rhd e e'}{bs \rhd e & bs' \rhd e'} &
	\infer{ 1_b \rhd e^\star}{} \\ \\
	\multicolumn{3}{c}{
		\infer{0_b\,(bs\,bss) \rhd e^\star}{bs \rhd e & bss \rhd e^\star}
	}
	\end{array}
	\]
	\centering
	\caption{Typing relation for bit-codes.}
	\label{figure:typing-bitcodes}
\end{figure}

The empty string and single character RE are both represented by empty bit lists. Codes for RE $e\,e'$ are
built by concatenating codes of $e$ and $e'$. In RE union operator, $+$, the bit $0_b$ marks that the
parse tree for $e + e'$ is built from $e$'s and bit $1_b$ that it is built from $e'$'s. For the Kleene
star, we use bit $1_b$ to denote the parse tree for the empty string and bit $0_b$ to begin matchings of $e$
in a parse tree for $e^\star$.

The relation between a bit-code and its underlying parse tree can be defined using functions
\code~ and \decodee, which generates a code for an input parse tree and builds a tree from a bit sequence, 
respectively. 
\[
\begin{array}{lcl}
   %\code\: :\:Tree\: \to\: e \to Code\\
   \code (() : \epsilon) & = & [\,]\\
   \code (a : a)         & = & [\,]\\
   \code (\inl\,t : e_1 + e_2) & = & 0_b\:\code(t : e_1)\\ 
   \code (\inr\,t : e_1 + e_2) & = & 1_b\:\code(t : e_2)\\
   \code (\langle t_1, t_2\rangle : e_1\,e_2) & = & \code (t_1 : e_1)\,\code(t_2 : e_2)\\
   \code ([\,] : e^\star) & = & 1_b\\
   \code ((t : ts) : e^\star) & = & 0_b\,\code (t : e)\:\code(ts : e^\star)\\ 
\end{array}
\]

Function \code~ has an immediate definition by recursion on the structure of a parse tree.
While coding a parse tree does not depend on its underlying RE, we keep it on
the \code~ function to follow its original definition~\cite{Lasse2011}.
In the definition of function \decodee, we use an auxiliary function, \decodeo, which 
threads the remaining bits in recursive calls.

\[
\begin{array}{lcl}
  \decodeo (bs : \epsilon) & = & ((), bs) \\
  \decodeo (bs : a)        & = & (a , bs) \\
  \decodeo (0_b\,bs : e_1 + e_2) & = & \leti\:(t,bs_1) = \decodeo (bs : e_1)\\
                                 &   & \iin\:(\inl\,t,bs_1)\\ 
  \decodeo (1_b\,bs : e_1 + e_2) & = & \leti\:(t,bs_2) = \decodeo (bs : e_2)\\
                                 &   & \iin\:(\inr\,t,bs_2)\\ 
  \decodeo (bs : e_1\,e_2) & = & \leti\:(t_1,bs_1) = \decodeo(bs : e_1) \\
                           &   & \,\,\,\,\,\,\,\,\,\,\,(t_2,bs_2) = \decodeo(bs_1 : e_2)\\
                           &   & \iin\:(\langle t_1,t_2\rangle, bs_2)\\
  \decodeo (1_b\,bs : e^\star) & = & ([\,],bs)\\
  \decodeo (0_b\,bs : e^\star) & = & \leti\:(t,bs_1) = \decodeo (bs : e)\\
                               &   & \,\,\,\,\,\,\,\,\,\,\,(ts,bs_2) = \decodeo(bs_1 : e ^\star) \\ 
                               &   & \iin\: ((t : ts), bs_2)\\
  \\
  \decodee (bs : e) & = & \leti\:(t,bs_1) = \decodeo(bs : e)\\
                    &   & \iin\:\iif\:bs_1 = [\,]\:\tthen\:t\:\eelse\:\eerror \\
\end{array}
\]

For single character and empty string REs, its decoding consists in just building
the tree and leaving the input bit-coded untouched. We build a left tree (using \inl)
for $e + e'$ if the code starts with bit $0_b$. A parse tree using constructor \inr~ is built
whenever we find bit $1_b$ for a union RE. Building a tree for concatenation is done by
sequencing the processing of codes for left component of concatenation and starting the
processing of right component with the remaining bits from the processing of the
left RE. Parsing the code for a Kleene star $e^\star$ consists in consuming a $0_b$, which
marks the beginning of the code for a match for $e$, followed for the code for a
tree for $e$ itself. We finish a list of matchings using a bit $1_b$.

\begin{Example}
We present again the same RE and string we showed in Example \ref{example:parsetree},
denoted by $((ab) + c)^*$ and $abcab$, respectively. Note that the parse tree is also the same.
However, this time we decorate trees with its bit codes. Bits introduced as
parse tree separators of the Kleene star were put as childs of the tree's root.
The first tree is built by the left operand of choice. Then it is marked by the
bit $0_b$. Second tree is built by choice's right operand and then is marked by
bit $1_b$. Last parse tree is again processed by the left
alternative of choice and then is represented by the bit $0_b$. Finally, we
finish the code using the bit $1_b$, which ends the matching list build by the
Kleene star operator.

\begin{center}
\begin{tikzpicture}[tlabel/.style={font=\footnotesize}]
\node{$[\,]$}
child{node{$0_b$}}  
child{
  node{$0_b$:\inl}
  child{
    node {$\langle,\rangle$}
    child{node{a}}
    child{node{b}}
  }
}
child{node{$0_b$}}
child{
  node{$1_b$:\inr}
  child{node {c}}
}
child{node{$0_b$}}
child{
  node{$0_b$:\inl}
  child{
    node {$\langle,\rangle$}
    child{node{a}}
    child{node{b}}
  }
}
child{node{$1_b$}};
\end{tikzpicture}
\end{center}

\end{Example}


The relation between codes and its correspondent parse trees is specified in the next
theorem.

\begin{Theorem}
  Let $t$ be a parse tree such that $\vdash t : e$, for some RE e. Then $(\code\: t\: e) \rhd e$ and
  $\decodee\:(\code\: t\: e)\,: e = t$.
\end{Theorem}
% \begin{proof}
%   Induction on the derivation of $\vdash t : e$.
% \end{proof}


\subsection{Dealing with problematic REs}\label{subsection:problematic}

A known problem in RE parsing is how to deal with the so-called problematic REs. A naive approach to 
parsing problematic REs can make the algorithm loop~\cite{Frisch2004}. Medeiros et al. \cite{Medeiros14}
present a function which converts a problematic RE into an equivalent non-problematic one.

The conversion function relies on two auxiliar definitions: one for testing if a RE accepts the empty string and 
another to test if a RE is equivalent to $\epsilon$. We name such functions as \nullable~ and \emptyy, 
respectively.

\[
\begin{array}{lcl}
   \nullable(\emptyset) & = & \bot \\ 
   \nullable(\epsilon)  & = & \top \\
   \nullable(a)         & = & \bot \\ 
   \nullable(e_1 + e_2) & = & \nullable(e_1)\lor\nullable(e_2)\\
   \nullable(e_1\:e_2)  & = & \nullable(e_1)\land\nullable(e_2)\\
   \nullable(e ^\star)  & = & \top \\
   \\
   \emptyy(\emptyset)    & = & \bot \\ 
   \emptyy(\epsilon)     & = & \top \\
   \emptyy(a)            & = & \bot \\
   \emptyy(e_1 + e_2)    & = & \emptyy(e_1) \land \emptyy(e_2)\\
   \emptyy(e_1\:e_2)     & = & \emptyy(e_1) \land \emptyy(e_2)\\
   \emptyy(e ^\star)     & = & \emptyy(e)\\        
\end{array}
\]

Functions \nullable~ and \emptyy~ obey the following correctness properties.


\begin{Lemma}
   \nullable($e$) = $\top$ if, and only if, $\epsilon\in\sembrackets{e}$.
\end{Lemma}
% \begin{proof}$\,$\\
%   $(\to)$ Induction over the structure of $e$. \\$(\leftarrow)$ Induction over the derivation of $\epsilon \in\sembrackets{e}$.
% \end{proof}

\begin{Lemma}
   If \emptyy($e$) = $\top$ then $e \approx \epsilon$.
\end{Lemma}
% \begin{proof}
%    Induction over the structure of $e$.
% \end{proof}


Given these two predicates, Medeiros et.al.~\cite{Medeiros14} define two mutually recursive functions,
named \fin~ and \fout. The function \fout~ recurses over the structure of an input RE
searching for a problematic sub-expression and \fin~ rewrites the Kleene star subexpression
so that it becomes non-problematic and preserves the language of the original 
RE. The definition of functions \fin~ and \fout~ are presented next.

\[
\begin{array}{lcl}
   \fout(e) & = & e,\,\texttt{if } e = \epsilon, e = \emptyset \texttt{ or } e = a\\
   \fout(e_1 + e_2) & = & \fout(e_1) + \fout(e_2) \\
   \fout(e_1\:e_2) & = & \fout(e_1)\:\fout(e_2)\\
   \fout(e^\star) & = & \left\{
        \begin{array}{ll}
           \fout(e)^\star & \texttt{if } \neg\,\nullable(e)\\
           \epsilon       & \texttt{if } \emptyy(e)\\
           \fin(e)^\star  & \texttt{otherwise}
        \end{array}
                          \right.
\end{array}
\]

\[
\begin{array}{lcl}
   \fin(e_1\:e_2) & = & \fin(e_1+e_2)\\
   \fin(e_1 + e_2) & = & \left\{
             \begin{array}{ll}
                \fin(e_2)  & \texttt{if }\emptyy(e_1) \land \nullable(e_2)\\
                \fout(e_2) & \texttt{if }\emptyy(e_1) \land \neg \nullable(e_2)\\
                \fin(e_1)  & \texttt{if }\nullable(e_1) \land \emptyy(e_2)\\
                \fout(e_1) & \texttt{if }\neg \nullable(e_1) \land \emptyy(e_2)\\
                \fout(e_1) + \fin(e_2) & \texttt{if }\neg \nullable(e_1) \land \neg\emptyy(e_2)\\
                \fin(e_1) + \fout(e_2) & \texttt{if }\neg \emptyy(e_1) \land \neg \nullable(e_2)\\
                \fin(e_1) + \fin(e_2) & \texttt{otherwise}
             \end{array}
                         \right. \\
   \fin(e^\star) & = & \left\{
             \begin{array}{ll}
               \fin(e) & \texttt{if }\nullable(e)\\
               \fout(e) & \texttt{otherwise}\\
             \end{array}
                       \right.
\end{array}
\]

The result of applying \fout~ on a RE is producing an equivalent non-problematic one. This fact is expressed
by the following theorem. 

\begin{Theorem}
   If $\fout(e) = e'$ then $e \approx e'$ and $e'$ is a non-problematic RE.
\end{Theorem}
% \begin{proof}
%    Well-founded induction on the complexity of $(e,s)$, where $s$ is an arbitrary string, using
%    several lemmas about RE equivalence and lemmas 1 and 2.
% \end{proof}

This result is proved (informally\footnote{By ``informally'', we mean that the
  result is not mechanized in a proof assistant.}) by Medeiros et. al.~\cite{Medeiros14}. In order to formalize this result
in Coq, we needed to prove several theorems about RE equivalence. We postpone the discussion on some details
of our formalization to Section \ref{section:formalization}.


\section{Proposed semantics for RE parsing}\label{section:semantics}

In this section we present the definition of a big step operational semantics
for a greedy RE parsing VM. The state of our VM is a pair formed by the current
RE and the string under parsing. Each machine 
transition produces as a result a bit-coded parse tree and the remaining string to be 
parsed. We denote our semantics by a judgement of the form $\langle e, s \rangle \leadsto^n (bs,s_p,s_r)$,
where $e$ is the current RE, $s$ is the input string, $n$ a step counter (used
in some inductive arguments about the semantics), $bs$ is the produced bit-coded tree, $s_p$ is
the parsed prefix of the input string and $s_r$ is the yet to be parsed string.
We let notation $\langle e, s \rangle\not\leadsto^n$ denote the fact that string
$s$ cannot be parsed by RE $e$. The semantics rules are presented in Figure~\ref{figure:bigstepsemantics}.

\begin{figure}
  \[
    \begin{array}{ccc}
        \infer[_{\{Emp\}}]{\langle \emptyset, s \rangle \not \leadsto^1}{} &
        \infer[_{\{Eps\}}]{\langle \epsilon, s\rangle \leadsto^1 ([\,],\epsilon,s)}{} &
        \infer[_{\{Chr1\}}]{\langle a, as\rangle\leadsto^1 ([\,],a,s)}{} \\ \\
        \infer[_{\{Chr2\}}]{\langle a, a'\,s \rangle \not\leadsto^1}{a \neq a'} &
        \infer[_{\{Chr3\}}]{\langle a, \epsilon \rangle\not\leadsto^1}{} &
        \infer[_{\{Cat1\}}]{\langle e_1\:e_2,s \rangle \not\leadsto^{1 + n}}
                           {\langle e_1,s \rangle\not\leadsto^n} \\ \\
      \multicolumn{3}{c}{
           \infer[_{\{Cat2\}}]{\langle e_1\:e_2,s_1s_2 \rangle \not\leadsto^{1 +
      n + m}}
                              {
                    \langle e_1, s_1s_2 \rangle \leadsto^n (bs_1, s_1, s_2) &
                    \langle e_2, s_2 \rangle \not\leadsto^m}
       }\\ \\
        \multicolumn{3}{c}{
            \infer[_{\{Cat3\}}]
                {\langle e_1\:e_2,s_1s_2s_r \rangle \leadsto^{1 + n + m}(bs_1\,bs_2,s_1s_2, s_r)}                                                              
                {\langle e_1, s_1s_2s_r \rangle \leadsto^n (bs_1,s_1,s_2s_r) &
                 \langle e_2, s_r \rangle \leadsto^m (bs_2, s_2, s_r)}
        } \\ \\
      \multicolumn{3}{c}{
          \infer[_{\{Ch1\}}]
                {\langle e_1+e_2,s_1s_r \rangle\leadsto^{1 + n} (0_b\,bs,s_1,s_r)}
                {\langle e_1, s_1s_r \rangle\leadsto^n (bs,s_1,s_r)}
      } \\ \\
      \multicolumn{3}{c}{
          \infer[_{\{Ch2\}}]
                {\langle e_1+e_2,s_2s_r \rangle\leadsto^{1 + n + m} (1_b\,bs,s_2,s_r)}
                {\langle e_1, s_2s_r \rangle\not\leadsto^n &
                 \langle e_2, s_2s_r \rangle\leadsto^m (bs,s_2,s_r)}
      } \\ \\
      \multicolumn{3}{c}{
          \infer[_{\{Ch3\}}]
                {\langle e_1+e_2,s \rangle\not\leadsto^{1 + n + m}}
                {\langle e_1, s \rangle\not\leadsto^n &
                 \langle e_2, s \rangle\not\leadsto^m }
      } \\ \\
      \infer[_{\{St1\}}]
      {\langle e_1^{\star},s \rangle\leadsto^{1 + n}(1_b,\epsilon,s)}
      {\langle e_1, s \rangle\not\leadsto^n} &
      \multicolumn{2}{c}{
          \infer[_{\{St2\}}]
                {\langle e_1^{\star},s_1s_2s_r \rangle\leadsto^{1 + n + m}(0_bbs\,bss,s_1s_2,s_r)}
                {\langle e_1, s_1s_2s_r \rangle\leadsto^n(bs,s_1,s_2s_r) &
                \langle e_1^{\star}, s_2s_r \rangle\leadsto^m(bss,s_2,s_r) }
      } \\ \\
      
    \end{array}
  \]
  \caption{Operational semantics for RE parsing.}
  \label{figure:bigstepsemantics}
\end{figure}


The meaning of each semantic rule in Figure~\ref{figure:bigstepsemantics} is as
follows. Rule $Emp$ says that the empty set RE fails on every input string and
rule $Eps$ specifies that parsing $s$ using RE $\epsilon$ produces 
an empty list of bits and does not consume any symbol from $s$. The rule $Chr1$
consumes the first symbol of the input string
if it matches the input RE and rules $Chr2$ and $Chr3$ handles the fail cases
(different first symbol or empty string).

Rules for star and choice operator encode the greedy disambiguation strategy
for RE parsing: first the parse tries the left operand of an alternative (rule
$Ch1$) and backtracks to try the right one only if the left fails (rule $Ch2$).
Rules for Klenne star follows the interpretation which matches the input
as many times as possible (rule $St2$). Parsing input using RE $e^\star$ stops
when $e$ fails (rule $St1$).



% Rule $Ch1$ specifies that to parse input using RE $e + e'$, by trying to
% parse the input using either the left or right subexpression. Note that, as a result, we append a bit $0_b$ when we successfully 
% parse the input using the left choice operand and the bit $1_b$ for a parsing using the right operand. Rule $CatVM$ defines 
% how a concatenation $e_1\,e_2$ is executed by the semantics: first, the input is parsed using the RE $e_1$ and the remaining 
% string is used as input to execute $e_2$. The bit-coded tree for the RE $e_1\,e_2$ is just the concatenation of the produced 
% codes for $e_1$ and $e_2$. Rules $NilVM$ and $ConsVM$ deal with unproblematic Kleene star REs. The rule $NilVM$ is only applicable when
% it is not possible to parse the input using the RE $e$ in $e^\star$. Rule $ConsVM$ can be used whenever we can parse the
% input using $e$ and the parsed prefix is not an empty string. The remaining string ($s_1$) of $e$'s parsing is used as
% input for the next iteration of RE $e^\star$ parsing. 

Our proposed semantics enjoy some important properties: 1) it is sound with
respect to standard RE inductive semantics; 2) it produces only valid parsing
results; 3) the semantics is determistic and 4) the successfull execution of the
semantics will consume a prefix of the input string. All these results were proved by
induction on the complexity of the pair $(e,s)$.

\begin{Theorem}[Soundness]\label{theorem:semanticssoundness}
  If $\langle e, s \rangle \leadsto^n (bs,s_p,s_r)$ then $s = s_p\,s_r$ and $s_p\in\sembrackets{e}$.
\end{Theorem}
% \begin{proof}
%   Well-founded induction on the complexity of $(e,s)$.
% \end{proof}

% \begin{Theorem}[Completeness]
%   If $s_p\in\sembrackets{e}$ then for all $s_r$ we have that exists $bs$, s.t. $\langle e, s_p\,s_r \rangle \leadsto (bs,s_p,s_r)$.
% \end{Theorem}
% \begin{proof}
%   Well-founded induction on the complexity of $(e,s)$.
% \end{proof}

\begin{Theorem}[Parsing result soundness]
  If $\langle e, s \rangle \leadsto^n (bs,s_p,s_r)$ then: 1) $bs \rhd e$; 2) $\flatten(\decodee(bs : e)) = s_p$; and 3)
  $\code(\decodee(bs : e) : e) = bs$. 
\end{Theorem}
% \begin{proof}
%   Well-founded induction on the complexity of $(e,s)$ using Theorem 3.
% \end{proof}

\begin{Theorem}[Determinism]\label{theorem:semanticsdeterministic}
  If $\langle e, s \rangle \leadsto^n r$ and $\langle e, s \rangle \leadsto^m r'$
  then $n = m$ and $r = r'$.
\end{Theorem}
% \begin{proof}
%   Induction on the step counter $n$ and case analysis on the derivation of
%   $\langle e, s \rangle \leadsto^m r'$.
% \end{proof}

Proof sketchs of these theorems can be found on~\ref{section:proofs-scketchs}.

\section{Coq formalization}\label{section:formalization}

In this section we describe the main design decisions in our formalization. At
the end of this section, we discuss how we extract a Haskell implementation from
our Coq development.

\paragraph{RE syntax and semantics} Our representation of RE syntax and
semantics is as usual in type-theory based proof assistants. We use an inductive
type to represent RE syntax and an inductive predicate to denote its semantics.

\begin{minted}{coq}
Inductive regex : Set :=
| Empty : regex | Eps : regex | Chr : ascii -> regex
| Cat : regex -> regex -> regex
| Choice : regex -> regex -> regex
| Star   : regex -> regex.
\end{minted}

Type \coq{regex} represents RE syntax and its definition is straightforward.
We use some notations to write \coq{regex} values. We let \verb|#0| denote
\coq{Empty}, \verb|#1| represents \coq{Eps}. Constructor \coq{Chr} is denoted by
\coq{$}, while infix operators \coq{:+:} and
\coq{@} denote \coq{Choice} and \coq{Cat}. Finally, \coq{Star e} is
written \coq{(e ^*)}. In our code presentation, we let \coq{``c''} denote
\coq{String c ``''}, for readability reasons.

RE semantics is represented by type \coq{in_regex} which has a constructor for each
rule of the semantics presented in Figure~\ref{figure:resemantics}.

\begin{minted}{coq}
Inductive in_regex : string -> regex -> Prop :=
| InEps : "" <<- #1
| InChr : forall c, "c" <<- ($ c)
| InLeft
  :  forall s e e'
  ,  s <<- e
  -> s <<- (e :+: e')
| InStarRight              
  : forall s s' e a s1 
  -> String a s <<- e
  -> s' <<- (e ^*)
  -> s1 = String a s ++ s'
  -> s1 <<- (e ^*)
...  (** some constructors omitted. *)
where "s '<<-' e" := (in_regex s e).
\end{minted}
We use notation \coq{s <<- e} to denote \coq{in_regex s e}.

\paragraph{RE equivalence} Using the previous presented semantics, we can define
RE equivalence by coding the standard definition in Coq as:
\begin{minted}{coq}
Definition regex_equiv (e e' : regex) : Prop :=
  forall s, s <<- e <-> s <<- e'.
\end{minted}
We use notation \coq{e1 === e2} to denote \coq{regex_equiv e1 e2}. In our
formalization, we proved that \coq{regex_equiv} is an equivalence relation,
which is necessary to allow the rewriting of such equalities by Coq
tactics.

In order to complete our formalization, we needed several results about RE
equivalence. Most of them are proved by well-founded induction on the complexity
of a pair formed by a RE and a string (defined in Section~\ref{subsection:resyntaxsemantics}).
In order to formalize the needed ordering relation, we take advantage of Coq's
standard library, which provides several combinators to assemble well-founded
relations. As an example, consider the following fact used by Medeiros et. al~\cite{Medeiros14} to
prove the correctness of its \fout~function: $(e_1 + e_2)^\star \approx
(e_1\,e_2)^\star$, which holds if both $e_1$ and $e_2$ accepts the empty string.
In our formalization such equivalence is proved by the following theorem proved
by well-founded induction.

\begin{minted}{coq}
Lemma choice_star_cat_star 
   : forall e1 e2, "" <<- e1 -> "" <<- e2 ->
                   ((e1 @ e2) ^*) === ((e1 :+: e2) ^*). 

\end{minted}
Several other lemmas about RE equivalence were proved in order to complete
the formalization of the problematic RE conversion function. We omit them
for brevity.

\paragraph{Converting problematic REs} The first step to certify the algorithm
for converting problematic REs into non-problematic ones is to define the
predicates for testing whether an input RE is nullable or whether it is equivalent to
$\epsilon$. We define such functions using dependently typed programming, i.e.
their types provide certificates that the result satisfies the desired correctness
property.

The nullability test is represented by function \coq{null}:
\begin{minted}{coq}
Definition null : forall e, {"" <<- e} + {~ "" <<- e}.
  refine (fix null e : {"" <<- e} + {~ "" <<- e} :=
            match e as e' return e = e' -> 
                    {"" <<- e'} + {~ "" <<- e'} with
            | #1 => fun Heq => Yes
            | e1 @ e2 => fun Heq =>
               match null e1 , null e2 with
               | Yes , Yes  => Yes
               | _ , _   => No
               end 
            | e1 :+: e2 => fun Heq => ...
            | e1 ^* => fun Heq => Yes
            end (eq_refl e)) ...
          (** some cases and tactics omitted *)
\end{minted}
Its type specifies that for any RE $e$ either $e$ accepts the empty string (i.e.
\coq{"" <<- e} holds) or not (\coq{~ "" <<- e}). Since such function contains
proofs terms, we use tactic \coq{refine} to define its computation content
leaving the logical subterms to be filled by tactics. The definition of
\coq{null} employs the convoy-pattern~\cite{Chlipala13}, which consists in
introducing an equality to allow the refinement of each equation type in
dependently typed pattern-matching.

In order to specify the emptyness test predicate, we use an inductive type
which characterizes when a RE is equivalent to $\epsilon$.
\begin{minted}{coq}
Inductive empty_regex : regex -> Prop :=
| Emp_Eps : empty_regex #1
| Emp_Cat : forall e e', empty_regex e ->
                    empty_regex e' ->
                    empty_regex (e @ e')
| Emp_Choice : forall e e', empty_regex e ->
                    empty_regex e' ->
                    empty_regex (e :+: e')
| Emp_Star : forall e, empty_regex e ->
                  empty_regex (e ^*).
\end{minted}
The meaning of each constructor of \coq{empty_regex} is as follows:
\coq{Emp_Eps} specifies that the empty RE is equivalent to itself.
For concatenation, choice and Kleene star, we can only say that they are
equivalent to $\epsilon$ if all of its subterms are also equivalent
to the empty RE.

Using the \coq{empty_regex} predicate we can easily prove the following
theorems. The first specifies that if \coq{empty_regex e} holds then
\coq{e} accepts the empty string and the second says that if
\coq{empty_regex e} is provable then \coq{e} is equivalent to the empty
string RE.

\begin{minted}{coq}
Lemma empty_regex_sem : forall e, empty_regex e -> "" <<- e.
Theorem empty_regex_spec : forall e, empty_regex e -> e === #1.
\end{minted}

The emptiness test function follows the same definition pattern as \coq{null}
using the \coq{refine} tactic. We specify its type using \coq{empty_regex}
predicate and we omit its definition for brevity.

Having defined these two predicates, we can implement the function to
convert problematic REs into non-problematic ones. The specification
of when a RE is not problematic is given by the following inductive predicate. 
\begin{minted}{coq}
Inductive unproblematic : regex -> Prop :=
| UEmpty : unproblematic #0
| UEps   : unproblematic #1
| UChr   : forall c, unproblematic ($ c)
| UCat   : forall e e', unproblematic e ->
                   unproblematic e' ->
                   unproblematic (e @ e')
| UChoice : forall e e', unproblematic e ->
                    unproblematic e' ->
                    unproblematic (e :+: e')
| UStar : forall e, ~ ("" <<- e) -> 
                   unproblematic e -> 
                   unproblematic (Star e).
\end{minted}
Type \coq{unproblematic} says that empty set, empty string and single
characters REs are unproblematic. Concatenation and choice REs are
unproblematic if both its subexpression are unproblematic. Finally,
a Kleene star is unproblematic if its subexpression is unproblematic and
does not accept the empty string. Finally, we specify the problematic RE
conversion function with the following type:
\begin{minted}{coq}
Definition unprob 
   : forall (e : regex), {e' | e === e' /\ unproblematic e'}.
\end{minted}
Function \coq{unprob} type says that from an input RE \coq{e} it returns another
RE \coq{e'} which is unproblematic and equivalent to \coq{e}. Again, we define
\coq{unprob} using \coq{refine} tactic and its definition is just the
Coq coding of \fout. As pointed by Medeiros et. al.~\cite{Medeiros14}, most of
the work to produce an unproblematic RE is done by function \fin, which is
applied when the inner RE of a Kleene star accepts the empty string and is not
equivalent to the empty RE. Function \coq{unprob_rec} implements \fin function
and we specify it with the following type:
\begin{minted}{coq}
Definition unprob_rec : forall e, "" <<- e -> ~ empty_regex e -> 
    {e' | (e ^*) === (e' ^*) /\ ~ "" <<- e' /\ unproblematic e'}
\end{minted}
\coq{unprob_rec}'s type estabilishes that the returned RE \coq{e'} is unproblematic, does not
accept the empty string and that its Kleene star is equivalent to input REs
Kleene star, i.e.  \coq{(e ^*) === (e' ^*)}.

\paragraph{Parse trees and bit-code representation}

In our formalization, we use the following inductive type to represent parse
trees:

\begin{minted}{coq}
Inductive tree : Set :=
| TUnit  : tree | TChr   : ascii -> tree
| TCat   : tree -> tree -> tree 
| TLeft  : tree -> tree | TRight : tree -> tree 
| TNil   : tree | TCons  : tree -> tree -> tree.
\end{minted}

Constructor \coq{TUnit} denotes a parse tree for the empty string RE,
\coq{TChr} the tree for a single symbol RE and \coq{TCat} the tree for
the concatenation of two REs. \coq{TLeft} and \coq{TRight} denote trees
for the choice operator. Constructors \coq{TCons} and \coq{TNil} can be
used to form a list of trees for a Kleene star RE.

The parse tree typing judgement is
coded as the following inductive predicate, in which each constructor
has a correspondent rule in Figure~\ref{figure:parsetreetyping}.

\begin{minted}{coq}
Inductive is_tree_of : tree -> regex -> Prop :=
| ITChr  : forall c, (TChr c) :> ($ c)
| ITCat  : forall e t e' t',
    t :> e   ->
    t' :> e' ->
    (TCat t t') :> (e @ e')
| ITLeft : forall e t e',
    t :> e ->
    (TLeft t) :> (e :+: e')
| ITCons : forall e t ts,
    t :> e ->
    ts :> (Star e) ->
    (TCons t ts) :> (Star e)
where "t ':>' e" := (is_tree_of t e).
(** some code ommited *)
\end{minted}
Function \flatten~(shown in Figure~\ref{figure:flatten}) has a direct encoding as a Coq recursive definition and
we omit it for brevity. From \flatten~ and tree typing relation definitions,
theorems \ref{theorem:semanticstypingflatten} and
\ref{theorem:typingflattensemantics} are easily proved.

Bit coding of parse trees is represented by a list of bits, as follows:
\begin{minted}{coq}
Inductive bit : Set := O : bit | I : bit.
Definition code := list bit.
\end{minted}
The typing relation for bit-coded parse trees
(Figure~\ref{figure:typing-bitcodes}) has an immediate definition as an
inductively defined Coq relation.
\begin{minted}{coq}
Inductive is_code_of : code -> regex -> Prop :=
| ICChar    : forall c, [] :# ($ c)
| ICLeft    : forall bs e e'
  , bs :# e ->
    (O :: bs) :# (e :+: e')
| ICCat : forall bs bs' e e'
  , bs :# e ->
    bs' :# e' ->
    (bs ++ bs') :# (e @ e')
| ICCons : forall e bs bss, 
    bs :# e -> 
    bss :# (e ^*) -> 
    (O :: bs ++ bss) :# (e ^*) 
where "bs ':#' e" := (is_code_of bs e).
(** some code omitted *)
\end{minted}
As with \flatten, function \code~has an immediate Coq definition. The next
results about \code~are proved by a routine inductive proof.
\begin{minted}{coq}
Lemma encode_sound
  : forall bs e, bs :# e -> exists t, t :> e /\ encode t = bs.
Lemma encode_complete
  : forall t e, t :> e -> (encode t) :# e.   
\end{minted}
Unlike \code, function \decodee~ has a more elaborate recursive definition, as
shown in Section~\ref{subsection:bitcodedparsetrees}, since it recurses over the
input RE while threading the remaining bits to be parsed into a tree. Since it
has a more complicated definition, we use dependent types to combine its definition
with its correctness proof. First, we define type \coq{nocode_for} which
denotes proofs that some bit list is not a valid bit-coded tree for some RE.
\begin{minted}{coq}
Inductive nocode_for : code -> regex -> Prop :=
| NCEmpty : forall bs, nocode_for bs #0
| NCChoicenil : forall e e', nocode_for [] (e :+: e')
| NCLBase : forall bs e e', 
    nocode_for bs e -> 
    nocode_for (O :: bs) (e :+: e')
| NCRBase : forall bs e e', 
    nocode_for bs e' -> 
    nocode_for (I :: bs) (e :+: e')
| NCStarnil : forall e, nocode_for [] (e ^*)
| NCStar : forall bs bs1 bs2 e,
      is_code_of bs1 e ->
      nocode_for bs2 (e ^*) ->
      bs = O :: bs1 ++ bs2  ->
      nocode_for bs (e ^*)
| NCStar1 : forall bs e,
    nocode_for bs e ->
    nocode_for (O :: bs) (e ^*).
(** some code omitted *)
\end{minted}
Constructor \coq{NCEmpty} specifies that there is no code for the empty RE,
\texttt{\#0}. For choice REs, we have several cases to cover. Constructor
\coq{NCChoicenil} specifies that the empty list is not a valid code for any
choice RE. Constructor \coq{NCLBase} (\coq{NCRBase}) specifies that if a list
isn't a valid code for a RE \coq{e} (\coq{e'}) it cannot be used to form a valid
code for \coq{e :+: e'}. In order to build a proof that some bit list isn't a
valid code for a concatenation RE, we just need to prove that it is not a code
for some of its sub-expressions. Finally, for the Kleene star, we have some
cases to cover: first, constructor \coq{NCStarnil} shows that the empty list
cannot be a code for any star RE. For non-empty bit-lists, it is just necessary
to show that some part of the bit list isn't a code either for \coq{e} or
\coq{e ^*}.

Using predicate \coq{nocode_for} we can define a type for invalid bit-codes:
\begin{minted}{coq}
Definition invalid_code bs e :=
  nocode_for bs e \/ exists t b1 bs1, bs = (encode t) ++ (b1 :: bs1).
\end{minted}
which basically says that a bit list is an invalid code for a RE \coq{e} when
either we can construct a proof of \coq{nocode_for} or we can parse a prefix of it into a
valid tree but it leaves a non-empty bit list as a remaining suffix. Using this
infrastructure, we can define the decode function with the following type:
\begin{minted}{coq}
Definition decode e bs : 
   {t | bs = encode t /\ is_tree_of t e} + {invalid_code bs e}.
\end{minted}
Note that the previous type denotes the correctness property of a decode
function: either it returns a valid tree for the input RE that can be
converted into the input bit list or a proof that such bit list isn't a valid
code for the input RE.

\paragraph{Formalizing the proposed semantics and its interpreter}

Our semantics definition consists of the Coq representation of the judgement in
Figure~\ref{figure:bigstepsemantics}, which is presented below. We use data-type
\coq{ouput} to represent success and failure cases in the semantics.
\begin{minted}{coq}
Inductive output : Set := 
| Ok    : string -> string -> code -> output
| Error : output.
\end{minted}
Constructor \coq{Ok} stores the parsed prefix, the remaining suffix and the
produced bit-code. The constructor \coq{Error} is used to represent a
parsing failure.

The semantics rules presented in Figure~\ref{figure:bigstepsemantics}, are
encoded as constructors of type \coq{greedy}, which relates the executed RE,
the input string, a step counter (value of type \coq{nat}) and the result,
of type \coq{output}.

\begin{minted}{coq}
Inductive greedy : regex -> string -> nat -> output -> Prop :=
| G_Empty
  : forall s, greedy #0 s 0 Error
| G_Eps
  : forall s, greedy #1 s 1 (Ok "" s [])
| G_ChrOk 
  : forall a s, greedy ($ a) (String a s) 2 (Ok (String a "") s [])
| G_Choice_Ok1 
  : forall e1 e2 s s1 r1 bs1 n,
    s = s1 ++ r1 ->
    greedy e1 s n (Ok s1 r1 bs1) ->
    greedy (e1 :+: e2) s (1 + n) (Ok s1 r1 (O :: bs1))
| G_Choice_Ok2
  : forall e1 e2 s s2 r2 bs2 n m,
    s = s2 ++ r2 ->
    greedy e1 s n Error ->
    greedy e2 s m (Ok s2 r2 bs2) -> 
    greedy (e1 :+: e2) s (1 + n + m) (Ok s2 r2 (I :: bs2))
| G_Star_Rec
  : forall e1 s s1 r1 bs1 s2 r2 bs2 n m,
    s = s1 ++ r1 ->
    greedy e1 s n (Ok s1 r1 bs1) ->
    r1 = s2 ++ r2 -> 
    greedy (Star e1) r1 m (Ok s2 r2 bs2) ->
    greedy (Star e1) s (1 + n + m) (Ok (s1 ++ s2) r2 (O :: bs1 ++ bs2))
| G_Star_Base
  : forall e1 s n,
    greedy e1 s n Error ->
    greedy (Star e1) s (1 + n) (Ok "" s (I :: [])).
(** some code omitted *)
\end{minted}

The main results of our semantics are stated below: soundness and determinism.
The soundness theorem is proved by induction on the complexity of the pair
$(e,s)$ and it is the Coq encoding of Theorem~\ref{theorem:semanticssoundness}.
\begin{minted}{coq}
Theorem greedy_sound
  : forall e s n s1 r1 bs1,
            s = s1 ++ r1 ->
            unproblematic e -> 
            greedy e s n (Ok s1 r1 bs1) ->
            s1 <<- e.
\end{minted}
Determinism of our semantics is proved by the next Coq theorem which encodes 
Theorem~\ref{theorem:semanticsdeterministic}.
\begin{minted}{coq}
Theorem greedy_deterministic
  : forall n e s o1, greedy e s n o1 ->
       forall m o2, greedy e s m o2  -> n = m /\ o1 = o2.
\end{minted}

After a proper definition of our semantics, we developed a formalized
interpreter for it. First, we need to define a type which ensures its
correctness. Type \coq{interp_type} uses type \coq{sumor} to encode the 
following property: eithter the intepreter returns a bit list which 
is a valid parsing evidence for the RE $e'$ which is a equivalent 
non-problematic RE to the input expression $e$ or either it returns a 
proof that the parsing process results in a error. 

\begin{minted}{coq}
Definition interp_type e s :=
  {bs : code | exists e', e === e' /\
               exists n cs rs, greedy e' s n (Ok cs rs bs) /\ bs :# e'} +
  {exists e' m, e === e' /\ greedy e' s m Error}.
\end{minted}

Building a term with an intricate dependent type such \coq{interp_type} is a
hard job. Some Coq extensions try to ease the task of dependently typed
programming~\cite{Sozeau10}. In this work, we avoid using such extensions and 
build our definition using tactics, which can be used to build programs. The 
code of our semantics intepreter is shown next.

The main interpreter logic is built by well-founded induction on the complexity
of the RE and input string. This is done using the following definitions. Type 
\coq{greedy_interp_type} gives a synonym for the interpreter of our semantics,
which basically takes a non-problematic RE and a string and returns a pair
formed by the step counter and a value of type \coq{output}, which represents
the parsing process result.

\begin{minted}{coq}
Definition greedy_interp_type e s :=
  unproblematic e -> {r | greedy e s (fst r) (snd r)}.
\end{minted}
Next, we define a function which encodes the intepreter logics by allowing 
recursion only on pairs which are structurally smaller than the input. This
style of programming is a way to define function of a complex recursive pattern 
in a total programming language, like Coq~\cite{Chlipala13}. 
Function \coq{greedy_interp_F} takes a pair $p = (e,s)$ formed by a RE and a string and a 
function which allows to recurse on smaller pairs and returns the result of 
executing the semantics on the input pair $p$.
\begin{minted}{coq}
Definition greedy_interp_F 
  : forall p, (forall p', input_lt p' p ->
                greedy_interp_type (get_regex p') (get_string p')) ->
         greedy_interp_type (get_regex p) (get_string p).
\end{minted}
Using function \coq{greedy_interp_F}, we build the intepreter for
non-problematic expressions: \coq{greedy_interp}, which is defined using Coq's 
library well-founded recursion combinator
\coq{well_founded_induction}~\cite{Bertot2010}.
\begin{minted}{coq}
Definition greedy_interp : forall e s, greedy_interp_type e s.
  intros e s Hu.
  change e with (get_regex (mk_input e s)) in *.
  change s with (get_string (mk_input e s)).
    apply (well_founded_induction
           wf_input_lt
           (fun p => 
                greedy_interp_type (get_regex p) (get_string p))
          ) ; eauto.
  apply greedy_interp_F.  
Defined.
\end{minted} 

Now that we have an intepreter for non-problematic RE, we just need to combine
it with function \coq{unprob} which converts the input RE into 
a non-problematic equivalent. 
\begin{minted}{coq}
Definition interp e s : interp_type e s.
  lets Hu : unprob e.
  destruct Hu as [e' [Heq' Hu']].
\end{minted}
Next, we just call function \coq{greedy_interp} which executes a non-problematic
RE over the input string and returns a semantics derivation corresponding to 
the parser execution. 
\begin{minted}{coq}
  assert (Hr : {r : nat * output | greedy e' s (fst r) (snd r)}).
  apply greedy_interp ; eauto.
\end{minted}
We finish the interpreter definition by pattern matching on \coq{greedy_interp}
results and applying lemmas which prove that: 1) assert that the input string is
the concatenation of the parsed prefix and the remaining suffix (lemma
\coq{greedy_prefix}) and the returned bit-coded parse tree is a valid for the 
RE.
\begin{minted}{coq}
  destruct Hr as [[n o] Hr] ; simpl in *.
  destruct o as [cs rs bs | ].
  -
    left ; exists* bs.
    exists e' ; splits* ; exists n cs rs ; splits*.
    assert (s = cs ++ rs) by (eapply greedy_sound ; eauto).
    eapply greedy_typed ; eauto.
  -
    right ; exists* e' n.
Defined.
\end{minted}


\paragraph{Extracting a certified implementation}

In order to obtain a certified Haskell implementation from our VM-based algorithm,
we use Coq support for extraction, which has several pre-defined
settings for using data-types and functions of Haskell's
Prelude\footnote{Prelude is the name of the Haskell library automatically loaded
in any Haskell module~\cite{Haskell98}.}.

The extracted Haskell code for our VM interpreter has 280 lines. In order to use 
the algorithm, we build a grep-like command line tool, which is avaliable at 
project's on-line repository~\cite{regexvm-rep}. 

\section{Evaluation}\label{section:experiments}

In this section we consider the performance of our VM for RE parsing. First, we 
develop an analytical model of its execution time and then consider its
performance againts some well-known REs used to test parsing algorithms.

\subsection{Analytical model}

Given an input non-problematic RE $e$, we will let $T(e)$ denote the 
time to execute $e$ over an input string $s$. We consider that $n$ denote
the length of the currently parsed input string. The definition of $T(e)$
is as follows:

\begin{figure}[H]
  \[
    \begin{array}{lcl}
      T(\emptyset)   & = & 1 \\
      T(\epsilon)    & = & 1 \\ 
      T(a)           & = & 1 \\ 
      T(e_1\,+\,e_2) & = & T(e_1) + T(e_2) \\
      T(e_1\:e_2)    & = & T(e_1) + T(e_2) \\
      T(e_1^*)       & = & n\times T(e_1) \\
    \end{array}
  \]
  \caption{Analytical model for VM execution time.}
  \label{figure:model}
\end{figure}

The execution time of the empty set, empty word and a 
single character RE is constant. The time needed to 
parse the concatenation or the choice of two RE is just the 
sum of their times.

Since our formalization deals only with non-problematic RE, 
each iteration of a Kleene star RE must consume, 
at least, one character. Since the input string has size 
$n$ and each match demands $T(e_1)$, total parsing time would
be $n\times T(e_1)$. 

The model allow us to show that time complexity of the 
proposed semantics is linear on the size of input string.
This property can be proved by structural induction on 
the executed RE.

\begin{Theorem}
  Let $e$ be an arbitrary unproblematic expression and $s$ arbitrary string.
  The execution time of $\langle e, s \rangle\leadsto r$ is $O(n)$, where $n = |s|$.
\end{Theorem}

\subsection{Experiments}

We use the formalized algorithm to build a Haskell tool for RE parsing and
compare its performance against the library
regex-applicative~\cite{regex-applicative}, which is an optimized library for RE
matching / parsing for Haskell. The reason for choosing this library is that it allows us to 
build bit coded parse trees using its applicative interface~\cite{Mcbride2008},
enabling a more fair comparison with our algorithm.
We ran our experiments on a machine with a Intel Core I7 1.7 GHz, 8GB RAM 
running Mac OS X 10.15.2 using GHC version 8.0.1; the results were collected
and the average of several test runs were computed. In order to allow
reproducibility, the on-line repository contains a Haskell program that
automates the task of running the experiments to produce the graphs presented next.

Also, we would like to emphasize that the intent of these experiments is not to
conclude that the proposed algorithm is more (less) efficient than the chosen 
library for RE parsing. Our main objective is to show that a fully verified
algorithm can have a performance comparable to an optimized library to the 
same task. 

The first experiment consists in parsing strings formed by a's by RE 
$(a + b + ab)^\star$ and the second with strings formed by ab's 
(examples taken from~\cite{Sulzmann14}). The results are presented in Figures
~\ref{fig:graph1} and~\ref{fig:graph2}.

\begin{figure}[h]
  \centering
  \begin{minipage}{0.45\textwidth}
    \includegraphics[width=.9\textwidth]{as.png}
    \caption{Results of experiment 1.}
    \label{fig:graph1}
  \end{minipage} \hfill
  \begin{minipage}{0.45\textwidth}
    \includegraphics[width=.9\textwidth]{abs.png}
    \caption{Results of experiment 2.}
    \label{fig:graph2}
  \end{minipage}
\end{figure}

When compared with regex-applicative, our tool exhibits a similar performance in
this test: both have a linear performance.

Another experiment considered was to parse strings $a$'s by the RE $(a +
\epsilon)^na^n$, where $a^n$ denotes $n \geq 0$ copies of $a$. Such RE poses a 
chalenge to RE parsing algorithms since they need to simulate the traversal of
$2^n$ paths, by backtracking, before finding a match~\cite{Lasse2011}. The
results of executing this experiment on increasing values of $n$ is presented 
in Figure~\ref{fig:graph3}.


\begin{figure}[h]
  \centering
  \begin{minipage}{0.45\textwidth}
    \includegraphics[width=.9\textwidth]{backtrack.png}
    \caption{Results of experiment 3.}
    \label{fig:graph3}
  \end{minipage} \hfill
  \begin{minipage}{0.45\textwidth}
    \includegraphics[width=.9\textwidth]{back1.png}
    \caption{Results of experiment 3 considering only the VM.}
    \label{fig:graph4}
  \end{minipage}
\end{figure}

In this example, our approach has a much better performance than
regex-applicative, which exhibits an exponential behaviour (also known as
catastrophic backtracking~\cite{Kirrage13}). Such bad 
behaviour on large REs can be explained by the NFA-based parsing algorithm  
used by regex-applicative library. Notice that our VM-based algorithm shows 
a linear performance on such problematic inputs, as expected by our
analytical model.

The last experiment considered is to test how both approaches perform
on random generated REs and random accepted strings for them. In order to
perform such test, we use Haskell library QuickCheck~\cite{Claessen2000}.
The experiment consists in collecting the result of running both semantics 
on thousands of input pairs formed by a RE and strings. The average of such 
executions is presented in the Figure~\ref{fig:graph5}, which shows that both 
algorithms exhibit a linear behaviour  on random inputs.

\begin{figure}[h]
    \includegraphics[width=0.6\textwidth]{random.png}
   \centering
   \caption{Results of experiment 4.}
   \label{fig:graph5}
\end{figure}

A few words should be written about how we generate random inputs. 
Generation of random RE is done by function \haskell{sizedRegex} with takes a depth limit to restrict
the size of the generated RE. Whenever the input depth limit is less or equal to 1, we can
only build a $\epsilon$ or a single character RE. The definition of \haskell{sizedRegex} uses
QuickCheck function \haskell{frequency}, which receives a list of pairs formed by a weight and
a random generator and produces, as result, a generator which uses such frequency distribution.
In \haskell{sizedRegex} implementation we give a higher weight to generate characters and equal distributions
to build concatenation, union or star.

\begin{minted}{haskell}
sizedRegex :: Int -> Gen Regex
sizedRegex n
  | n <= 1 = frequency [ (10, return Eps), (90, Chr <$> genChar) ]
  | otherwise = frequency [ (10, return Epsilon), (30, Chr <$> genChar)
         , (20, Cat <$> sizedRegex n2 <*> sizedRegex n2)
         , (20, Choice <$> sizedRegex n2 <*> sizedRegex n2)
         , (20, Star  <$> sizedRegex n2)]
         where n2 = div n 2
\end{minted}


Given an RE $e$, we can generate a random string $s$ such that $s \in\sembrackets{e}$
using the next definition. We generate strings by choosing randomly between branches of
a union or by repeating $n$ times a string $s$ which is accepted by $e$, whenever we
have $e^\star$ (function \haskell{randomMatches}).

\begin{minted}{haskell}
randomMatch :: Regex -> Gen String
randomMatch Eps = return ""
randomMatch (Chr c) = return [c]
randomMatch (Cat e e') = liftM2 (++) (randomMatch e)
                                     (randomMatch e')
randomMatch (Choice e e') = oneof [ randomMatch e, randomMatch e' ]
randomMatch (Star e) = do
      n <- choose (0,3) :: Gen Int
      randomMatches n e

randomMatches :: Int -> Regex -> Gen String
randomMatches m e'
  | m <= 0 = return []
  | otherwise = liftM2 (++) (randomMatch e')
                            (randomMatches (m - 1) e')
\end{minted}

\section{Related works}\label{section:related}

Ierusalimschy~\cite{Ierusalimschy2009} proposed the use of Parsing Expression Grammars (PEGs) as a basis
for pattern matching. He argued that pure REs are a weak formalism for pattern-matching tasks:
many interesting patterns either are difficult to describe or cannot be described by REs. He also said
that the inherent non-determinism of REs does not fit the need to capture specific parts of a match. Following
this proposal, he presented LPEG, a pattern-matching tool based on PEGs for the Lua language. He
argued that LPEG unifies the ease of use of pattern-matching tools with the full expressive power of PEGs.
He also presented a parsing machine that allows an implementation of PEGs for pattern matching.
Medeiros et. al.~\cite{Medeiros2008} presents informal correctness proofs of LPEG parsing machine.
While such proofs represent an important step towards the correctness of LPEG, there is no guarantee that LPEG
implementation follows its specification.

Rathnayake and Thielecke~\cite{Rathnayake2011} formalized a VM implementation for RE matching using
operational semantics. Specifically, they derived a series of abstract machines, moving from the abstract
definition of matching to realistic machines. First, a continuation is added to the operational semantics
to describe what remains to be matched after the current expression. Next, they represented the expression
as a data structure using pointers, which enables redundant searches to be eliminated via testing for pointer
equality. Although their work has some similarities with ours (a VM-based parsing of REs), they did not present
any evidence or proofs that their VM is correct.

Fischer, Huch and Wilke~\cite{Fischer2010} developed a Haskell program for matching REs. Their program is purely
functional and it is overloaded over arbitrary semirings, which solves the matching problem and supports other
applications like computing leftmost longest matchings or the number of matchings. Their program can also be used
for parsing every context-free language by taking advantage of laziness. Their developed program is based on an
old technique to turn REs into finite automata, which makes it efficient compared to other similar approaches.
One advantage of their implementation over our proposal is that their approach works with context-free languages,
not only with REs purely. However, they did not present any correctness proof of their Haskell code.

Cox~\cite{Cox2009} said that viewing RE matching as executing a special machine makes it possible to add new
features just by the inclusion of new machine instructions. He presented two different ways to implement
a VM that executes a RE that has been compiled into  byte-codes: a recursive and a non-recursive
backtracking implementation, both in C programming language. Cox's work on VM-based RE parsing is poorly specified:
both the VM semantics and the RE compilation process are described only informally
and no correctness guarantees are even mentioned.

Frisch and Cardelli~\cite{Frisch2004} studied the theoretical problem of matching a flat sequence against a type (RE): the
result of the process is a structured value of a given type. Their contributions were in noticing that: (1) A disambiguated
result of parsing can be presented as a data structure that does not contain ambiguities. (2) There are problematic cases in
parsing values of star types that need to be disambiguated. (3) The disambiguation strategy used in XDuce and CDuce (two
XML-oriented functional languages) pattern matching can be characterized mathematically by what they call greedy RE matching.
(4) There is a linear time algorithm for the greedy matching. Their approach is different since they want to axiomatize abstractly
the disambiguation policy, without providing an explicit matching algorithm. They identified three notions of problematic words, REs,
and values (which represent the ways to match words), related these three notions, and proposed matching algorithms to deal with the
problematic case.

Ribeiro and Du Bois~\cite{Ribeiro2017} described the formalization of a RE parsing algorithm that produces a bit representation
of its parse tree in the dependently typed language Agda. The algorithm computes bit-codes using Brzozowski derivatives and
they proved that the produced codes are equivalent to parse trees ensuring soundness and completeness with respect to an
inductive RE semantics. They included the certified algorithm in a tool developed by themselves, named verigrep, for RE-based
search in the style of GNU grep. While the authors provided formal proofs, their tool show a bad performance when compared to
other approaches to RE parsing.

Nielsen and Henglein~\cite{Lasse2011} showed how to generate a compact bit-coded representation of a parse tree for a
given RE efficiently, without explicitly constructing the parse tree first, by simplifying the DFA-based parsing algorithm of
Dub and Feeley~\cite{Dube2000} to emit a bit representation without explicitly materializing the parse tree itself.
They also showed that Frisch and Cardellis greedy RE parsing algorithm~\cite{Frisch2004} can be straightforwardly modified to
produce bit codings directly. They implemented both solutions as well as a backtracking parser and performed benchmark experiments
to measure their performance. They argued that bit codings are interesting in their own right since they are typically not
only smaller than the parse tree, but also smaller than the string being parsed and can be combined with other techniques for
improved text compression. As others related works, the authors did not present a formal verification of their implementations.

Sulzmann et. al.~\cite{Sulzmann14} propose an algorithm for POSIX RE parsing
with uses RE derivatives to construct parse trees incrementally to solve both 
matching and submatching for REs. In order to improve the
efficiency of the proposed algorithm, Sulzmann et al. use a bit encoded representation of RE parse trees. Textual proofs of
correctness of the proposed algorithm are presented in an appendix.
Ausaf et. al.~\cite{Ausaf16} present a Isabelle/HOL formalization of Sulzmann et. al POSIX
parsing algorithm. They gave their inductive definition of what a
POSIX value is and showed that such a value is unique for a given RE and a
string being matched. We intend, as future work, to use a similar inductive
definition to characterize the disambiguation strategy followed by our VM semantics.

A recent application of REs was presented by Radanne \cite{Radanne2019}. In many
cases, the goal of a RE is not only to match a given text, but also to extract 
information from it. With that in mind, the author presented a technique to 
provide type-safe extraction based on the typed interpretation of REs. That 
technique relies on two-layer REs in which the upper layer allows to compose and 
transform data in a well-typed way, while the lower one is composed by untyped
REs that can leverage features from a preexisting RE matching engine. Results 
showed that this technique is faster than other two libraries that perform the 
same task, despite its lack of efficiency when compared with some full RE 
parsing algorithms. No formalization was provided in that work.

Radanne and Thiemann \cite{radanne:hal-01788827} pointed that some of the
algorithms for RE matching are rather intricate and the natural question 
that arises is how to test these algorithms. It is not too hard to come 
up with generators for strings that match a given RE, but on the other hand, 
the algorithms should reject strings that do not match that RE. So it is 
equally important to come up with strings that do not match. In other words, 
a satisfactory solution for testing such matchers would require generating 
positive as well as negative examples for some language. Thus, the authors 
presented an algorithm to generate the language of a generalized RE with union, 
intersection and complement operators. Using this technique, they could generate 
both positive and negative instance of a RE. They provided two implementations: 
one in Haskell, which explores different algorithmic improvements, and one in 
OCaml, which evaluates choices in data structures. Their algorithm lacks of 
correctness proofs. 

Groz and Maneth \cite{Groz2017} approached the efficiency of testing and
matching of deterministic REs. They presented a linear time algorithm for
testing whether a RE is deterministic and an efficient algorithm for matching
 words against deterministic REs. It was shown that an input word of length 
$n$ can be matched against a deterministic RE of length $m$ in time 
$O (m + n  \log \log m)$. If the deterministic RE has bounded depth 
of alternating union and concatenation operators, then matching can be
 performed in time $O (m + n)$. According to the authors, these results 
extend to REs containing numerical occurrence indicators. The authors 
presented the concept of deterministic REs and the differences between weak 
and strong determinism. Their paper contains some proofs, many of them related 
to algorithmic running time. However, their approach was focused on performance 
over deterministic REs, leaving aside the non-deterministic ones. We intend to 
investigate time complexity of algorithm in future works. 

A formal constructive theory of RLs was presented by Doczkal et. al. in
\cite{Doczkal2013}. They formalized some fundamental results about RLs. 
For their formalization, they used the Ssreflect extension to Coq, which 
features an extensive library with support for reasoning about finite 
structures such as finite types and finite graphs. They established all 
of their results in about 1400 lines of Coq, half of which are specifications. 
Most of their formalization deals with translations between different 
representations of RLs, including REs, DFAs, minimal DFAs and NFAs. 
They formalized all these (and other) representations and constructed 
computable conversions between them. Besides other interesting aspects 
of their work, they proved the decidability of language equivalence 
for all representations. Unlike our work, Doczkal et. al.'s only concerns 
about formalizing classical results of RL theory in Coq, without using the 
formalized automata in practical applications, like matching or parsing.  

A new technique for constructing a finite deterministic automaton from a 
RE was presented by Asperti et al in \cite{Asperti10}. It's based on the 
idea of marking a suitable set of positions inside the RE, intuitively 
representing the possible points reached after the processing of an initial 
prefix of the input string. In other words, the points mark the positions 
inside the RE which have been reached after reading some prefix of the 
input string, or better positions where the processing of the remaining 
string has to be started. Each pointed expression for a RE $e$ represents 
a state of the deterministic automaton associated with $e$; since there 
is obviously only a finite number of possible labellings, the number 
of states of the automaton is finite. The authors argued that 
Pointed REs join the elegance and the symbolic appealingsness of 
Brzozowski's derivatives with the effectiveness of McNaughton and 
Yamada's labelling technique, essentially combining the best of the 
two approaches, allowing a direct, intuitive and easily verifiable 
construction of the deterministic automaton for $e$. The authors said 
that pointed expressions can provide a more compact description for 
RLs than traditional REs. However, the authors do not discuss the 
usage of pointed REs for parsing or matching.

The concept of prioritized transducers to formalize capturing groups in RE
matching was introduced by Berglund and Merwe \cite{Berglund2016}. Their main
goal was to provide an automata-based theoretical foundation for the basic
functionality of modern RE matchers (with a focus on the Java RE standard
library). Many RE matching libraries perform matching as a form of parsing by 
using capturing groups, and thus output what subexpression matched which
substring. Their approach permits an analysis of matching semantics of a 
subset of the REs supported in Java. According to the authors, converting REs 
to what they called as prioritized transducers is a natural generalization of 
the Thompson construction for REs to NFA.

\section{Conclusion}\label{section:conclusion}

In this work, we presented a big-step operational semantics for a virtual
machine for greedy RE parsing. 
Our semantics produces, as parsing evidence, bit-codes. In order to avoid the well-known problems with 
problematic REs, we use an algorithm that converts a problematic RE into an equivalent non-problematic one.
All theoretical results reported in this paper are intregrally verified using
Coq proof assistant. 
From our formalization, we extract a Haskell implementation of our algorithm and used it to build 
a tool for RE parsing, which has performance comparable to a optimized Haskell library
for RE parsing. The complete development is avaliable at~\cite{regexvm-rep}.

As future work we intend to extend our semantics with some real-world regex
features like capture groups and quantifiers, while keeping an easy to follow
formalization and an efficient algorithmic interpreter for it. Other line of
research we intend to pursue is to characterize Medeiros et.
al.~\cite{Medeiros14} construction of non-problematic RE in terms of the 
coinductive axiomatization of Heinglein et. al.~\cite{Henglein2011}.


\section*{Acknowledgements}

This work is supported by the CNPq  Brazil under grant No.: 426232/2016.

\section*{References}

\bibliography{references}

\appendix

\section{A tour of Coq proof assistant}\label{section:coq}

Coq is a proof assistant based on the calculus of inductive
constructions (CIC)~\cite{Bertot2010}, a higher-order typed
$\lambda$-calculus extended with inductive definitions. Theorem
proving in Coq follows the ideas of the so-called
``BHK-correspondence''\footnote{Abbreviation of Brower, Heyting,
  Kolmogorov, de Bruijn and Martin-L\"of Correspondence. This is also
  known as the Curry-Howard ``isomorphism''.}, in which types represent
logical formulas, $\lambda$-terms represent proofs, and the task of
checking if a piece of text is a proof of a given formula corresponds
to type-checking (i.e. checking if the term that represents the proof
has the type corresponding to the given formula)~\cite{Sorensen2006}.

Writing a proof term whose type is that of a logical formula can be
however a hard task, even for simple propositions.  In order to make
this task easier, Coq provides \emph{tactics}, which are commands that
can be used to help the user in the construction of proof terms.

In this section we provide a brief overview of Coq. We start with a
small example, that uses basic
features of Coq --- types, functions and proof definitions.  In this
example, we use an inductive type that represents natural numbers in
Peano notation. The \coq{nat} type definition includes an
annotation, that indicates that it belongs to the \coq{Set}
sort\footnote{Coq's type language classifies new inductive (and
  co-inductive) definitions by using sorts. \coq{Set} is the sort
  of computational values (programs) and \coq{Prop} is the sort of
  logical formulas and proofs.}. Type \coq{nat} is formed by two
data constructors: \coq{O}, that represents the number $0$, and \coq{S},
the successor function.
\begin{minted}{coq}
Inductive nat : Set :=
| O : nat
| S : nat -> nat.

Fixpoint plus (n m : nat) : nat :=
   match n with
   | O => m
   | S n' => S (plus n' m)
   end.

Theorem plus0r : forall n, plus n 0 = n.
Proof.
   intros n. induction n.
   reflexivity.
   simpl. rewrite -> IHn. reflexivity.
Qed.
\end{minted}   

Command \coq{Fixpoint} allows the definition of functions by
structural recursion. The definition of \coq{plus}, for summing two
values of type \coq{nat}, is straightforward. It should be noted
that all functions defined in Coq must be total.

Besides declaring inductive types and functions, Coq allows us to
define and prove theorems. In our example, we show a simple theorem
about \coq{plus}, that states that
\coq{plus n 0 = n}, for an arbitrary value \coq{n} of type
\coq{nat}. Command \coq{Theorem} allows the statement of a
formula that we want to prove and starts the \emph{interactive proof mode}, 
in which tactics can be used to produce the proof term that
is the proof of such formula. In the example, various tactics are
used to prove the desired result.  The first tactic, \coq{intros}, is
used to move premisses and universally quantified variables from the
goal to the hypothesis. Tactic \coq{induction} is used to start an inductive
proof over an inductively defined object (in our example,
the natural number \coq{n}), generating a case for each constructor and
an induction hypothesis for each recursive branch in constructors.
Tactic \coq{reflexivity} proves trivial equalities up to conversion and
\coq{rewrite} is used to replace terms using some equality. 

For each inductively defined data type,
Coq generates automatically an induction principle~\cite[Chapter
14]{Bertot2010}. For natural numbers, the following Coq term, called
\coq{nat_ind}, is created: 
\begin{minted}{coq}
nat_ind
     : forall P : nat -> Prop,
       P O -> (forall n : nat, P n -> P (S n)) ->
       forall n : nat, P n
\end{minted}
It expects a property (\coq{P}) over natural numbers (a value of type
\coq{nat -> Prop}), a proof that \coq{P} holds for zero (a value of
type \coq{P 0}) and a proof that if \coq{P} holds for an arbitrary
natural \coq{n}, then it holds for \coq{S n} (i.e. a value of type
\coq{forall n:nat, P n -> P (S n)}). Besides \coq{nat_ind}, generated by
the use of tactic \coq{induction}, the term below 
uses the constructor of the equality
type \coq{eq_refl}, created by tactic \coq{reflexivity}, and term
\coq{eq_ind_r}, inserted by the use of tactic \coq{rewrite}. Term
\coq{eq_ind_r} allows concluding \coq{P y} based on the assumptions
that \coq{P x} and \coq{x = y} are provable.

\begin{minted}{coq}
Definition plus_0_r_term :=
	fun n : nat =>
		nat_ind
		   (fun n0 : nat => plus n0 O = n0) (eq_refl O)
		   (fun (n' : nat) (IHn' : plus n' O = n') =>
		      eq_ind_r (fun n0 : nat => S n0 = S n')
		               (eq_refl (S n')) IHn') n
		: forall n : nat, plus n O = n
\end{minted}  

Instead of using tactics, one could instead write CIC terms directly
to prove theorems.  This can be however a complex task, even for
simple theorems like \coq{plus_0_r}, because it generally requires
detailed knowledge of the CIC type system.

An interesting feature of Coq is the possibility of defining inductive
types that mix computational and logical parts. Such types are usually
called \emph{strong specifications}, since they allow the definition
of functions that compute values together with a proof that this value
has some desired property. As an example, consider type \coq{sig}
below, also called ``subset type'', that is defined in Coq's standard
library as:
\begin{minted}{coq}
Inductive sig (A : Set)(P : A -> Prop) : Set :=
 | exist : forall x : A, P x -> sig A P.
\end{minted}

Type \coq{sig} is usually expressed in Coq by using the following
syntax: $\{x : A \,\vert\,P\:x\}$.
Constructor \coq{exist} has two
parameters. Parameter \coq{x : A} represents the
computational part. The other parameter, of type \coq{P x}, denotes
the ``certificate'' that \coq{x} has the property specified by
predicate \coq{P}. As an example, consider:
\begin{minted}{coq}
forall n : nat, n <> 0 -> {m | n = S m}
\end{minted}
This type can be used to specify a function that returns the
predecessor of a natural number \coq{n}, together with a proof that
the returned value really is the predecessor of \coq{n}. The
definition of a function of type \coq{sig} requires the specification
of a logical certificate. As occurs in the case of theorems, tactics
can be used in the definition of such functions. For example, a
definition of a function that returns the predecessor of a given
natural number, if it is different from zero, can be given as follows:

\begin{minted}{coq}
Definition predcert : forall n : nat, n <> 0 -> {m | n = S m}.
   intros n H.
   destruct n.
   destruct H. reflexivity.
   exists n. reflexivity.
Defined.
\end{minted}

Tactic \coq{destruct} is used to start a proof by case analysis on
structure of a value.

Another example of a type that can be used to provide strong
specifications in Coq is \coq{sumor}, that is defined in the
standard library as follows:
\begin{minted}{coq}
Inductive sumor(A : Set) (B : Prop) : Set :=
| inleft : A -> sumor A B
| inright : B -> sumor A B.
\end{minted}

Coq standard library also provides syntactic sugar (or, in Coq's
terminology, notations) for using this type: ``\coq{sumor A B}'' can
be written as \coq{A + {B}}.
This type can be used as the type of a function that returns either a
value of type \coq{A} or a proof that some property specified by
\coq{B} holds.
As an example, we can specify the type of a function that returns a
predecessor of a natural number or a proof that the given number is
equal to zero as follows, using type \coq{sumor}:
\begin{minted}{coq}
 {p | n = S p} + {n = 0}
\end{minted}  
A common problem when using rich specifications for functions is the need
of writing proof terms inside its definition body. A possible solution for
this is to use the \coq{refine} tactic, which allows one to specify a term with
missing parts (knowns as ``holes'') to be filled latter using tactics.

The next code piece uses the \coq{refine} tactic to build the computational part
of a certified predecessor function. We use holes to mark positions where proofs are
expected. Such proof obligations are later filled by tactic \coq{reflexivity} which finishes
\coq{predcert} definition.

\begin{minted}{coq}
Definition predcert : forall n : nat, {p | n = S p} + {n = 0}.
  refine (fun n =>
            match n with
            | O => inright _
            | S n' => inleft _ (exist _ n' _)
            end) ; reflexivity.
Defined.
\end{minted}

The same function can be defined in a more suscint way using notations introduced
in~\cite{Chlipala13}.

\begin{minted}{coq}
Definition predcert : forall n : nat, {p | n = S p} + {n = 0}.
  refine (fun n =>
            match n with
            | O => !!
            | S n' => [|| n' ||]
            end) ; reflexivity.
Defined.
\end{minted}
The utility of notations is to hide the writing of constructors and holes in
function definitions.

% Another useful type for specifications is \coq{maybe}, which allows a proof
% obligation-free failure for some predicate~\cite{Chlipala13}.
% \begin{minted}{coq}
% Inductive maybe (A : Set) (P : A -> Prop) : Set :=
% | Unknown : maybe P
% | Found : forall x : A, P x -> maybe P.
% \end{minted}
% Using \coq{maybe}, we can define a certified predecessor function as:
% \begin{minted}{coq}
% Definition predcert : forall n : nat, {{m | n = S m}}.
%   refine (fun n =>
%     match n return {{m | n = S m}} with
%       | O => ??
%       | S n' => [ n' ]
%     end); trivial.
% Defined.
% \end{minted}
% The previous definition uses some notations: first, type \coq{maybe P} is
% denoted by \coq{{{x | P}}}. Constructor \coq{Unknown} is represented by \coq{??}
% and \coq{Found n} by \coq{[ n ]}. In our development, we use these
% specification types to define several certified functions. More details about
% these will be given in Section \ref{section:formalization}.

A detailed discussion on using Coq is out of the scope of this paper. Good introductions
to Coq proof assistant are avaliable elsewhere~\cite{Bertot2010,Chlipala13}.

\section{Proof Sketchs}\label{section:proofs-scketchs}

\begin{Theorem*}[Soundness]
  If $\langle e, s \rangle \leadsto^n (bs,s_p,s_r)$ then $s = s_p\,s_r$ and $s_p\in\sembrackets{e}$.
\end{Theorem*}
\begin{proof}
  The proof follows by well-founded induction on the complexity of $(e,s)$. We will
  show some cases. The cases for $emptyset$, $\epsilon$ and a single symbol RE
  are immediate. In the case of the concatenation, we have that $e = e_1\:e_2$,
  $\langle e_1, s \rangle\leadsto^{n_1}(bs_1,s_1,s_2)$ and
  $\langle e_2, s \rangle\leadsto^{n_2}(bs_2,s_3,s_4)$. By the induction
  hypothesis, we have that $s_1\in\sembrackets{e_1}$ $s = s_1s_2$,
  $s = s_1 s_2$, $s_3\in\sembrackets{e_2}$ $s_2 = s_3s_4$. The result follows
  by using these equalities and rule $Cat$.\\
  When $e = e_1 + e_2$, we need to consider two possibilities:
  \begin{itemize}
    \item Last rule used in derivation of $\langle e_1 + e_2, s \rangle
      \leadsto^n (bs,s_p,s_r)$ was $Ch1$: Then,
      $\langle e_1, s \rangle \leadsto^{n_1} (bs_1,s_p,s_r)$, $bs = 0_bbs_1$ and
      $n = 1 + n_1$. The conclusion follows by using the induction hypothesis
      and rule $Left$.
    \item Last rule used in derivation of $\langle e_1 + e_2, s \rangle
      \leadsto^n (bs,s_p,s_r)$ was $Ch2$: Then,
      $\langle e_1, s \rangle \not\leadsto^{n_1}$,
      $\langle e_2, s \rangle \leadsto^{m} (bs_1,s_p,s_r)$, $bs = 1_bbs_1$ and
      $n = 1 + n_1 + m$. The conclusion follows by using the induction hypothesis
      and rule $Right$.
  \end{itemize}
\end{proof}

\begin{Theorem*}[Parsing result soundness]
  If $\langle e, s \rangle \leadsto^n (bs,s_p,s_r)$ then: 1) $bs \rhd e$; 2) $\flatten(\decodee(bs : e)) = s_p$; and 3)
  $\code(\decodee(bs : e) : e) = bs$. 
\end{Theorem*}
\begin{proof}
  The proof follows by well-founded induction on the complexity of $(e,s)$. We
  will show some cases. The cases for $emptyset$, $\epsilon$ and a single symbol RE
  are immediate. When $e = e_1\,e_2$, we have that
    $\langle e_1, s \rangle\leadsto^{n_1}(bs_2,s_1,s_2)$ and
  $\langle e_2, s \rangle\leadsto^{n_2}(bs_2,s_3,s_4)$. By the induction
  hypothesis on $e_1$ we have that $bs_1 \rhd e_1$, $\flatten(\decodee(bs_1 : e_1)) =
  s_1$ and $\code(\decodee(bs_1 : e_1) : e_1) = bs_1$. 
By the induction
  hypothesis on $e_2$ we have that $bs_2 \rhd e_2$, $\flatten(\decodee(bs_2 : e_2)) =
  s_2$ and $\code(\decodee(bs_2 : e_2) : e_2) = bs_2$. The results follow by the
  definition of bit-codes typing and definitions of functions $\flatten$,
  $\code$ and $\decodee$. 
\end{proof}

\begin{Theorem*}[Determinism]
  If $\langle e, s \rangle \leadsto^n r$ and $\langle e, s \rangle \leadsto^m r'$
  then $n = m$ and $r = r'$.
\end{Theorem*}
\begin{proof}
  Induction on the step counter $n$ and case analysis on the derivation of
  $\langle e, s \rangle \leadsto^m r$. We will show some cases. When $n = 0$,
  we have that $e = \emptyset$ and the result follows. When $n = 1$, we have
  that $e = \epsilon$ and again the result follows. Now suppose that $n \geq 2$
  and $e = e_1 + e_2$. Consider the following cases for the last rule used to
  deduce $\langle e_1 + e_2, s \rangle \leadsto^n r$.
  \begin{itemize}
    \item Rule $Ch1$: Then, we have that $\langle e_1, s \rangle \leadsto^{n_1}
      (bs, s_1, s_2)$ and $n = 1 + n_1$. The result follows by case analysis on the
      derivation $\langle e_1 + e_2, s \rangle \leadsto^{m}
      r'$ and the induction hypothesis.
    \item Rule $Ch2$: Then, we have $\langle e_1, s \rangle \not\leadsto^{n_1}$,
      $\langle e_2, s \rangle \leadsto^{m_1} (bs, s_1, s_2)$ and $n = 1 + n_1 +
      m_1$. Now, we do a case analysis on $r'$. When $r'$ is a failure, the 
      result follows. When $r' = (bs', s_1', s_2')$, the result follows by 
      the induction hypothesis.
  \end{itemize}
\end{proof}


\begin{Theorem*}
  Let $e$ be an arbitrary unproblematic expression and $s$ arbitrary string.
  The execution time of $\langle e, s \rangle\leadsto r$ is $O(n)$, where $n = |s|$.
\end{Theorem*}
\begin{proof}
  Induction on the structure of $e$. The only interesting case is for the
  star operator. In this case, we have that $e = e_1^\star$.
  Since $e$ is unproblematic, then
  $\epsilon \not\in\sembrackets{e_1}$ and it consumes, at each iteration step,
  at least one symbol from input. Since the input size is $n$, then the
  desired result follows.
\end{proof}


\end{document}
