@article{Lopes2018,
	author = {Lopes, Raul Felipe Pimenta},
	title = {{Certified Derivative-based Parsing of Regular Expressions --- Master Thesis.}},
	year = {2018}
}

@article{Ierusalimschy2009,
	author = {Ierusalimschy, Roberto},
	doi = {10.1002/spe.892},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ierusalimschy - 2009 - A text patternmatching tool based on parsing expression grammars.pdf:pdf},
	issn = {00380644},
	journal = {Software - Practice and Experience},
	keywords = {Parsing expression grammars,Pattern matching,Scripting languages},
	mendeley-groups = {Directly related},
	title = {{A text patternmatching tool based on parsing expression grammars}},
	year = {2009}
}

@article{Cox2009,
	author = {Cox, Russ},
	title = {{Regular Expression Matching: the Virtual Machine Approach}},
	url = {https://swtch.com/{~}rsc/regexp/regexp2.html},
	year = {2009}
}

@article{Fischer2010,
	author = {Fischer, Sebastian and Huch, Frank and Wilke, Thomas},
	doi = {10.1145/1932681.1863594},
	isbn = {9781605587943},
	issn = {03621340},
	journal = {ACM SIGPLAN Notices},
	keywords = {a laptop,a whiteboard next to,finite automata,glushkov con-,h azel sitting at,her desk,keyboard,nearby,purely functional programming,regular expressions,struction,the desk,to the left,two office chairs},
	mendeley-groups = {Directly related},
	number = {9},
	pages = {357},
	title = {{A play on regular expressions}},
	volume = {45},
	year = {2010}
}

@article{Frisch2004,
	author = {Frisch, Alain and Cardelli, Luca},
	journal = {ICALP 2004 - International Colloquium on Automata, Languages and Programming},
	mendeley-groups = {Novos},
	pages = {618--629},
	title = {{Greedy Regular Expression Matching}},
	volume = {3142},
	year = {2004}
}

@article{Ribeiro2017,
	author = {Ribeiro, Rodrigo and Bois, Andr{\'{e}} Du},
	isbn = {9781450353892},
	journal = {Proceedings of the 21st Brazilian Symposium on Programming Languages  - SBLP 2017},
	keywords = {bit-codes,certi ed algorithms,dependent,regular expressions},
	mendeley-groups = {Novos},
	pages = {1--8},
	title = {{Certified Bit-Coded Regular Expression Parsing}},
	url = {http://dl.acm.org/citation.cfm?doid=3125374.3125381},
	year = {2017}
}

@article{Nielsen2011,
	author = {Nielsen, Lasse and Henglein, Fritz},
	isbn = {9783642212536},
	issn = {16113349},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	mendeley-groups = {Novos},
	pages = {402--413},
	title = {{Bit-coded Regular Expression Parsing}},
	volume = {6638 LNCS},
	year = {2011}
}

@article{Medeiros2008,
	abstract = {Parsing Expression Grammar (PEG) is a recognition-based foundation for describing syntax that renewed interest in top-down parsing approaches. Generally, the implementation of PEGs is based on a recursive-descent parser, or uses a memoization algorithm.},
	author = {Medeiros, S{\'{e}}rgio and Ierusalimschy, Roberto},
	doi = {10.1145/1408681.1408683},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Medeiros, Ierusalimschy - 2008 - A parsing machine for PEGs.pdf:pdf},
	isbn = {9781605582702},
	journal = {Proceedings of the 2008 symposium on Dynamic languages - DLS '08},
	keywords = {parsing expression grammars,parsing machine,pattern},
	mendeley-groups = {Novos},
	pages = {1--12},
	title = {{A parsing machine for PEGs}},
	url = {http://portal.acm.org/citation.cfm?doid=1408681.1408683},
	year = {2008}
}

@article{Grathwohl2014,
	author = {Grathwohl, Niels Bj{\o}rn Bugge and Henglein, Fritz and Rasmussen, Ulrik Terp},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grathwohl, Henglein, Rasmussen - 2014 - A Crash-Course in Regular Expression Parsing and Regular Expressions as Types.pdf:pdf},
	mendeley-groups = {Novos},
	title = {{A Crash-Course in Regular Expression Parsing and Regular Expressions as Types}},
	year = {2014}
}

@book{Hutton2007,
	abstract = {Haskell is one of the leading languages for teaching functional programming, enabling students to write simpler and cleaner code, and to learn how to},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {Hutton, Graham},
	booktitle = {Solutions},
	doi = {10.1017/S0956796809007151},
	eprint = {arXiv:1011.1669v3},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hutton - 2007 - Programming in Haskell.pdf:pdf},
	isbn = {0521692695},
	issn = {1098-6596},
	mendeley-groups = {Directly related},
	pages = {1--184},
	pmid = {25246403},
	title = {{Programming in Haskell}},
	year = {2007}
}

@unpublished{etheses6011,
	month = {July},
	title = {Semantics, analysis and security of backtracking regular expression matchers},
	school = {University of Birmingham},
	author = {Asiri Rathnayake },
	year = {2015},
	url = {http://etheses.bham.ac.uk/6011/},
}

@article{Rathnayake2011,
	archivePrefix = {arXiv},
	arxivId = {1108.3126},
	author = {Rathnayake, Asiri and Thielecke, Hayo},
	doi = {10.4204/EPTCS.62.3},
	eprint = {1108.3126},
	issn = {2075-2180},
	journal = {Electronic Proceedings in Theoretical Computer Science},
	mendeley-groups = {New Articles},
	number = {Sos},
	pages = {31--45},
	title = {{Regular Expression Matching and Operational Semantics}},
	url = {http://arxiv.org/abs/1108.3126},
	volume = {62},
	year = {2011}
}

@book{Pierce2000,
	author = {Pierce, Benjamin},
	booktitle = {ACM SIGPLAN Notices},
	doi = {10.1145/360271.360273},
	isbn = {0262162091},
	issn = {03621340},
	mendeley-groups = {Books},
	number = {8},
	pages = {20--30},
	title = {{Types and Programming Languages}},
	url = {http://portal.acm.org/citation.cfm?doid=360271.360273},
	volume = {35},
	year = {2000}
}
@article{Knuth71,
 author = {Knuth, Donald E.},
 title = {Top-down Syntax Analysis},
 journal = {Acta Inf.},
 issue_date = {June      1971},
 volume = {1},
 number = {2},
 month = jun,
 year = {1971},
 issn = {0001-5903},
 pages = {79--110},
 numpages = {32},
 url = {http://dx.doi.org/10.1007/BF00289517},
 doi = {10.1007/BF00289517},
 acmid = {2698042},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
} 
@inproceedings{Ford04,
 author = {Ford, Bryan},
 title = {Parsing Expression Grammars: A Recognition-based Syntactic Foundation},
 booktitle = {Proceedings of the 31st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
 series = {POPL '04},
 year = {2004},
 isbn = {1-58113-729-X},
 location = {Venice, Italy},
 pages = {111--122},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/964001.964011},
 doi = {10.1145/964001.964011},
 acmid = {964011},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {BNF, GTDPL, TDPL, context-free grammars, lexical analysis, packrat parsing, parsing expression grammars, regular expressions, scannerless parsing, syntactic predicates, unified grammars},
}
@inproceedings{Firsov13,
 author = {Firsov, Denis and Uustalu, Tarmo},
 title = {Certified Parsing of Regular Languages},
 booktitle = {Proceedings of the Third International Conference on Certified Programs and Proofs - Volume 8307},
 year = {2013},
 isbn = {978-3-319-03544-4},
 pages = {98--113},
 numpages = {16},
 url = {http://dx.doi.org/10.1007/978-3-319-03545-1_7},
 doi = {10.1007/978-3-319-03545-1_7},
 acmid = {2695040},
 publisher = {Springer-Verlag New York, Inc.},
 address = {New York, NY, USA},
} 
@InProceedings{Sulzmann14,
author="Sulzmann, Martin
and Lu, Kenny Zhuo Ming",
editor="Codish, Michael
and Sumii, Eijiro",
title="POSIX Regular Expression Parsing with Derivatives",
booktitle="Functional and Logic Programming",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="203--220",
isbn="978-3-319-07151-0"
}
@book{Hopcroft2000,
 author = {Hopcroft, John E. and Motwani, Rajeev and Rotwani and Ullman, Jeffrey D.},
 title = {Introduction to Automata Theory, Languages and Computability},
 year = {2000},
 isbn = {0201441241},
 edition = {2nd},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
} 
@Misc{Grep,
  key =      {Grep},
  title =    {{GNU Grep home page}},
  howpublished = {\verb+https://www.gnu.org/software/grep/+},
}
@inproceedings{Hutton98,
        title = "{Fold and Unfold for Program Semantics}",
        author = "Graham Hutton",
        booktitle = "{Proceedings of the 3rd ACM SIGPLAN International
                Conference on Functional Programming}",
        address = "Baltimore, Maryland",
        month = sep,
        year = 1998}
@inproceedings{Lopes2016,
  author    = {Raul Lopes and Rodrigo Ribeiro and
               Carlos Camar{\~{a}}o},
  title     = {Certified Derivative-Based Parsing of Regular Expressions},
  booktitle = {Programming Languages --- Lecture Notes in Computer Science 9889},
  pages     = {95--109},
  year      = {2016},
  publisher = {Springer}
}
@article{Asperti10,
  author    = {Andrea Asperti and
               Claudio Sacerdoti Coen and
               Enrico Tassi},
  title     = {Regular Expressions, au point},
  journal   = {CoRR},
  volume    = {abs/1010.2604},
  year      = {2010},
  url       = {http://arxiv.org/abs/1010.2604},
  archivePrefix = {arXiv},
  eprint    = {1010.2604},
  timestamp = {Wed, 07 Jun 2017 14:40:15 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1010-2604},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@book{Hindley2008,
 author = {Hindley, J. Roger and Seldin, Jonathan P.},
 title = {Lambda-Calculus and Combinators: An Introduction},
 year = {2008},
 isbn = {0521898854, 9780521898850},
 edition = {2},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
}
@InProceedings{Ausaf16,
author="Ausaf, Fahad
and Dyckhoff, Roy
and Urban, Christian",
editor="Blanchette, Jasmin Christian
and Merz, Stephan",
title="POSIX Lexing with Derivatives of Regular Expressions (Proof Pearl)",
booktitle="Interactive Theorem Proving",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="69--86",
isbn="978-3-319-43144-4"
}
@InProceedings{Lasse2011,
author="Nielsen, Lasse
and Henglein, Fritz",
editor="Dediu, Adrian-Horia
and Inenaga, Shunsuke
and Mart{\'i}n-Vide, Carlos",
title="Bit-coded Regular Expression Parsing",
booktitle="Language and Automata Theory and Applications",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="402--413",
isbn="978-3-642-21254-3"
}
@article{Thompson1968,
 author = {Thompson, Ken},
 title = {Programming Techniques: Regular Expression Search Algorithm},
 journal = {Commun. ACM},
 issue_date = {June 1968},
 volume = {11},
 number = {6},
 month = jun,
 year = {1968},
 issn = {0001-0782},
 pages = {419--422},
 numpages = {4},
 acmid = {363387},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {match, regular expression, search},
} 

@inproceedings{Claessen2000,
 author = {Claessen, Koen and Hughes, John},
 title = {QuickCheck: A Lightweight Tool for Random Testing of Haskell Programs},
 booktitle = {Proceedings of the Fifth ACM SIGPLAN International Conference on Functional Programming},
 series = {ICFP '00},
 year = {2000},
 isbn = {1-58113-202-6},
 pages = {268--279},
 numpages = {12},
 acmid = {351266},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
@article{Claessen:2000:QLT:357766.351266,
 author = {Claessen, Koen and Hughes, John},
 title = {QuickCheck: A Lightweight Tool for Random Testing of Haskell Programs},
 journal = {SIGPLAN Not.},
 issue_date = {Sept. 2000},
 volume = {35},
 number = {9},
 month = sep,
 year = {2000},
 issn = {0362-1340},
 pages = {268--279},
 numpages = {12},
 acmid = {351266},
 publisher = {ACM},
 address = {New York, NY, USA},
}
@book{Aho1986,
 author = {Aho, Alfred V. and Sethi, Ravi and Ullman, Jeffrey D.},
 title = {Compilers: Principles, Techniques, and Tools},
 year = {1986},
 isbn = {0-201-10088-6},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
}
@inproceedings{AbbottAGM03,
  author    = {Michael Gordon Abbott and
               Thorsten Altenkirch and
               Neil Ghani and
               Conor McBride},
  title     = {Derivatives of Containers},
  booktitle = {Typed Lambda Calculi and Applications, 6th International Conference,
               {TLCA} 2003, Valencia, Spain, June 10-12, 2003, Proceedings.},
  pages     = {16--30},
  year      = {2003},
  crossref  = {DBLP:conf/tlca/2003},
  url       = {https://doi.org/10.1007/3-540-44904-3_2},
  doi       = {10.1007/3-540-44904-3_2},
  timestamp = {Mon, 29 May 2017 16:53:44 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/tlca/AbbottAGM03},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@proceedings{DBLP:conf/tlca/2003,
  editor    = {Martin Hofmann},
  title     = {Typed Lambda Calculi and Applications, 6th International Conference,
               {TLCA} 2003, Valencia, Spain, June 10-12, 2003, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {2701},
  publisher = {Springer},
  year      = {2003},
  url       = {https://doi.org/10.1007/3-540-44904-3},
  doi       = {10.1007/3-540-44904-3},
  isbn      = {3-540-40332-9},
  timestamp = {Mon, 29 May 2017 16:53:44 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/tlca/2003},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@book{Lipovaca2011,
 author = {Lipovaca, Miran},
 title = {Learn You a Haskell for Great Good!: A Beginner's Guide},
 year = {2011},
 isbn = {1593272839, 9781593272838},
 edition = {1st},
 publisher = {No Starch Press},
 address = {San Francisco, CA, USA},
}
@misc{Loh2005,
    author = {Loh, A.},
    citeulike-article-id = {430095},
    citeulike-linkout-0 = {http://www.cs.uu.nl/\~{}andres/lhs2TeX-IFIP.pdf},
    keywords = {haskell, typesetting},
    posted-at = {2005-12-07 19:12:30},
    priority = {4},
    title = {{Typesetting Haskell and more with lhs2TeX}},
    url = {http://www.cs.uu.nl/\~{}andres/lhs2TeX-IFIP.pdf}
}
@book{Felleisen2009,
 author = {Felleisen, Matthias and Findler, Robert Bruce and Flatt, Matthew},
 title = {Semantics Engineering with PLT Redex},
 year = {2009},
 isbn = {0262062755, 9780262062756},
 edition = {1st},
 publisher = {The MIT Press},
}
@inproceedings{McBride08,
  author    = {Conor McBride},
  title     = {Clowns to the left of me, jokers to the right (pearl): dissecting
               data structures},
  booktitle = {Proceedings of the 35th {ACM} {SIGPLAN-SIGACT} Symposium on Principles
               of Programming Languages, {POPL} 2008, San Francisco, California,
               USA, January 7-12, 2008},
  pages     = {287--295},
  year      = {2008},
  crossref  = {DBLP:conf/popl/2008},
  url       = {http://doi.acm.org/10.1145/1328438.1328474},
  doi       = {10.1145/1328438.1328474},
  timestamp = {Tue, 22 May 2012 15:24:56 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/popl/McBride08},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Brzozowski1964,
 author = {Brzozowski, Janusz A.},
 title = {Derivatives of Regular Expressions},
 journal = {J. ACM},
 issue_date = {Oct. 1964},
 volume = {11},
 number = {4},
 month = oct,
 year = {1964},
 issn = {0004-5411},
 pages = {481--494},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/321239.321249},
 doi = {10.1145/321239.321249},
 acmid = {321249},
 publisher = {ACM},
 address = {New York, NY, USA},
}
@article{Gluskov1961,
  added-at = {2009-01-14T00:43:43.000+0100},
  author = {Glushkov, Victor M.},
  biburl = {https://www.bibsonomy.org/bibtex/2e41c06da6b174517bb5142f37da6aabb/dret},
  description = {dret'd bibliography},
  interhash = {42c3be081fb5d9caea8db07a14048b50},
  intrahash = {e41c06da6b174517bb5142f37da6aabb},
  journal = {Russian Mathematical Surveys},
  keywords = {imported},
  number = 5,
  pages = {1-53},
  timestamp = {2009-01-14T00:43:44.000+0100},
  title = {The Abstract Theory of Automata},
  uri = {http://www.turpion.org/php/paper.phtml?journal_id=rm&paper_id=4112},
  volume = 16,
  year = 1961
}
@book{Bertot2010,
 author = {Bertot, Yves and Castran, Pierre},
 title = {Interactive Theorem Proving and Program Development: Coq'Art The Calculus of Inductive Constructions},
 year = {2010},
 isbn = {3642058809, 9783642058806},
 edition = {1st},
 publisher = {Springer Publishing Company, Incorporated},
} 
@inproceedings{Gill2007,
 author = {Gill, Andy and Runciman, Colin},
 title = {Haskell Program Coverage},
 booktitle = {Proceedings of the ACM SIGPLAN Workshop on Haskell Workshop},
 series = {Haskell '07},
 year = {2007},
 isbn = {978-1-59593-674-5},
 location = {Freiburg, Germany},
 pages = {1--12},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1291201.1291203},
 doi = {10.1145/1291201.1291203},
 acmid = {1291203},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {code coverage, haskell, software engineering},
}
@article{Dube2000,
 author = {Dub{\'e}, Danny and Feeley, Marc},
 title = {Efficiently Building a Parse Tree from a Regular Expression},
 journal = {Acta Inf.},
 issue_date = {2000},
 volume = {37},
 number = {2},
 month = oct,
 year = {2000},
 issn = {0001-5903},
 pages = {121--144},
 numpages = {24},
 url = {http://dx.doi.org/10.1007/s002360000037},
 doi = {10.1007/s002360000037},
 acmid = {361193},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
} 
@inproceedings{SulzmannL14,
  author    = {Martin Sulzmann and
               Kenny Zhuo Ming Lu},
  title     = {{POSIX} Regular Expression Parsing with Derivatives},
  booktitle = {Functional and Logic Programming - 12th International Symposium, {FLOPS}
               2014, Kanazawa, Japan, June 4-6, 2014. Proceedings},
  pages     = {203--220},
  year      = {2014},
  crossref  = {DBLP:conf/flops/2014},
  url       = {http://dx.doi.org/10.1007/978-3-319-07151-0_13},
  doi       = {10.1007/978-3-319-07151-0_13},
  timestamp = {Fri, 23 May 2014 14:56:52 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/flops/SulzmannL14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@misc{regexvm-rep,
  author = {Delfino, Thales and Ribeiro, Rodrigo}, 
  title   = {Towards certified virtual machine-based regular expression parsing  --- On-line repository}, 
  howpublished = {https://github.com/thalesad/regexvm},
  year    = {2018}
}
@article{COQUAND198895,
title = "The calculus of constructions",
journal = "Information and Computation",
volume = "76",
number = "2",
pages = "95 - 120",
year = "1988",
issn = "0890-5401",
doi = "https://doi.org/10.1016/0890-5401(88)90005-3",
url = "http://www.sciencedirect.com/science/article/pii/0890540188900053",
author = "Thierry Coquand and Gérard Huet"
}
@book{Sorensen2006,
 author = {S{\o}rensen, Morten Heine and Urzyczyn, Pawel},
 title = {Lectures on the Curry-Howard Isomorphism, Volume 149 (Studies in Logic and the Foundations of Mathematics)},
 year = {2006},
 isbn = {0444520775},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
}
@inproceedings{McBride15,
  author    = {Conor McBride},
  title     = {Turing-Completeness Totally Free},
  booktitle = {Mathematics of Program Construction - 12th International Conference,
               {MPC} 2015, K{\"{o}}nigswinter, Germany, June 29 - July 1, 2015.
               Proceedings},
  pages     = {257--275},
  year      = {2015},
  crossref  = {DBLP:conf/mpc/2015},
  url       = {https://doi.org/10.1007/978-3-319-19797-5\_13},
  doi       = {10.1007/978-3-319-19797-5\_13},
  timestamp = {Mon, 22 May 2017 17:11:14 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/mpc/McBride15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@proceedings{DBLP:conf/mpc/2015,
  editor    = {Ralf Hinze and
               Janis Voigtl{\"{a}}nder},
  title     = {Mathematics of Program Construction - 12th International Conference,
               {MPC} 2015, K{\"{o}}nigswinter, Germany, June 29 - July 1, 2015.
               Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {9129},
  publisher = {Springer},
  year      = {2015},
  url       = {https://doi.org/10.1007/978-3-319-19797-5},
  doi       = {10.1007/978-3-319-19797-5},
  isbn      = {978-3-319-19796-8},
  timestamp = {Mon, 22 May 2017 17:11:14 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/mpc/2015},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{BoveKS16,
  author    = {Ana Bove and
               Alexander Krauss and
               Matthieu Sozeau},
  title     = {Partiality and recursion in interactive theorem provers - an overview},
  journal   = {Mathematical Structures in Computer Science},
  volume    = {26},
  number    = {1},
  pages     = {38--88},
  year      = {2016},
  url       = {https://doi.org/10.1017/S0960129514000115},
  doi       = {10.1017/S0960129514000115},
  timestamp = {Sun, 28 May 2017 13:25:37 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/mscs/BoveKS16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Landin64,
author = {Landin, P. J.},
title = {The Mechanical Evaluation of Expressions},
journal = {The Computer Journal},
volume = {6},
number = {4},
pages = {308-320},
year = {1964},
doi = {10.1093/comjnl/6.4.308},
URL = {http://dx.doi.org/10.1093/comjnl/6.4.308},
eprint = {/oup/backfile/content_public/journal/comjnl/6/4/10.1093/comjnl/6.4.308/2/6-4-308.pdf}
}
@article{Krivine07,
 author = {Krivine, Jean-Louis},
 title = {A Call-by-name Lambda-calculus Machine},
 journal = {Higher Order Symbol. Comput.},
 issue_date = {September 2007},
 volume = {20},
 number = {3},
 month = sep,
 year = {2007},
 issn = {1388-3690},
 pages = {199--207},
 numpages = {9},
 url = {http://dx.doi.org/10.1007/s10990-007-9018-9},
 doi = {10.1007/s10990-007-9018-9},
 acmid = {1325153},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Control instruction, Curry-Howard correspondence, Lambda-calculus machine},
}
@article{Medeiros14,
 author = {Medeiros, S{\'e}rgio and Mascarenhas, Fabio and Ierusalimschy, Roberto},
 title = {From Regexes to Parsing Expression Grammars},
 journal = {Sci. Comput. Program.},
 issue_date = {November, 2014},
 volume = {93},
 month = nov,
 year = {2014},
 issn = {0167-6423},
 pages = {3--18},
 numpages = {16},
 url = {http://dx.doi.org/10.1016/j.scico.2012.11.006},
 doi = {10.1016/j.scico.2012.11.006},
 acmid = {2664811},
 publisher = {Elsevier North-Holland, Inc.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 keywords = {Natural semantics, Parsing expression grammars, Pattern matching, Regexes, Regular expressions},
} 
@inproceedings{Delfino18,
 author = {Delfino, Thales Ant\^{o}nio and Ribeiro, Rodrigo},
 title = {Towards Certified Virtual Machine-based Regular Expression Parsing},
 booktitle = {Proceedings of the XXII Brazilian Symposium on Programming Languages},
 series = {SBLP '18},
 year = {2018},
 isbn = {978-1-4503-6480-5},
 location = {Sao Carlos, Brazil},
 pages = {67--74},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/3264637.3264646},
 doi = {10.1145/3264637.3264646},
 acmid = {3264646},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {operational semantics, parsing, regular expressions, virtual machines},
} 
@book{Chlipala13,
 author = {Chlipala, Adam},
 title = {Certified Programming with Dependent Types: A Pragmatic Introduction to the Coq Proof Assistant},
 year = {2013},
 isbn = {0262026651, 9780262026659},
 publisher = {The MIT Press},
} 
@inproceedings{McBride15,
  author    = {Conor McBride},
  title     = {Turing-Completeness Totally Free},
  booktitle = {{MPC}},
  series    = {Lecture Notes in Computer Science},
  volume    = {9129},
  pages     = {257--275},
  publisher = {Springer},
  year      = {2015}
}
@book{Haskell98,
  added-at = {2008-01-15T20:00:13.000+0100},
  biburl = {https://www.bibsonomy.org/bibtex/274578ea79af534c544b545401a50d6e5/thau},
  description = {This report defines the syntax for Haskell programs and an informal abstract semantics for the meaning of such programs.},
  editor = {Jones, Simon Peyton},
  howpublished = {PDF},
  interhash = {bdf24915989dc1673ad9244c4d593b37},
  intrahash = {74578ea79af534c544b545401a50d6e5},
  keywords = {functional-programming haskell},
  month = {September},
  pages = 277,
  publisher = {http://haskell.org/},
  timestamp = {2008-01-15T20:00:13.000+0100},
  title = {Haskell 98 Language and Libraries: The Revised Report},
  type = {Language Definition},
  url = {http://haskell.org/definition/haskell98-report.pdf},
  year = 2002
}
@misc{regex-applicative,
  author = {Cheplyaka, Roman}, 
  title   = {regex-applicative: Regex based parsing with applicative interface  --- On-line repository}, 
  howpublished = {http://hackage.haskell.org/package/regex-applicative},
  year    = {2018}
}
@article{Mcbride2008,
 author = {Mcbride, Conor and Paterson, Ross},
 title = {Applicative Programming with Effects},
 journal = {J. Funct. Program.},
 issue_date = {January 2008},
 volume = {18},
 number = {1},
 month = jan,
 year = {2008},
 issn = {0956-7968},
 pages = {1--13},
 numpages = {13},
 url = {http://dx.doi.org/10.1017/S0956796807006326},
 doi = {10.1017/S0956796807006326},
 acmid = {1348941},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
} 
@InProceedings{Kirrage13,
author="Kirrage, James
and Rathnayake, Asiri
and Thielecke, Hayo",
editor="Lopez, Javier
and Huang, Xinyi
and Sandhu, Ravi",
title="Static Analysis for Regular Expression Denial-of-Service Attacks",
booktitle="Network and System Security",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="135--148",
abstract="Regular expressions are a concise yet expressive language for expressing patterns. For instance, in networked software, they are used for input validation and intrusion detection. Yet some widely deployed regular expression matchers based on backtracking are themselves vulnerable to denial-of-service attacks, since their runtime can be exponential for certain input strings. This paper presents a static analysis for detecting such vulnerable regular expressions. The running time of the analysis compares favourably with tools based on fuzzing, that is, randomly generating inputs and measuring how long matching them takes. Unlike fuzzers, the analysis pinpoints the source of the vulnerability and generates possible malicious inputs for programmers to use in security testing. Moreover, the analysis has a firm theoretical foundation in abstract machines. Testing the analysis on two large repositories of regular expressions shows that the analysis is able to find significant numbers of vulnerable regular expressions in a matter of seconds.",
isbn="978-3-642-38631-2"
}
@inproceedings{Radanne2019,
	author = {Radanne, Gabriel},
	title = {Typed Parsing and Unparsing for Untyped Regular Expression Engines},
	booktitle = {Proceedings of the 2019 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation},
	series = {PEPM 2019},
	year = {2019},
	isbn = {978-1-4503-6226-9},
	location = {Cascais, Portugal},
	pages = {35--46},
	numpages = {12},
	url = {http://doi.acm.org/10.1145/3294032.3294082},
	doi = {10.1145/3294032.3294082},
	acmid = {3294082},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {Functional programming, OCaml, Regular expressions, Static typing, unparsing},
}
@article{Bruggemann-Klein1992,
	abstract = {It is a well-established fact that each regular expression can be transformed into a nondeterministic finite automaton (NFA) with or without $\epsilon$-transitions, and all authors seem to provide their own variant of the construction. Of these, Berry and Sethi (1986) have shown that the construction of an $\epsilon$-free NFA due to Glushkov (1961) is a natural representation of the regular expression because it can be described in terms of Brzozowski derivatives (Brzozowski 1964) of the expression. Moreover, the Glushkov construction also plays a significant role in the document processing area: The SGML standard (ISO 8879 1986), now widely adopted by publishing houses and government agencies for the syntactic specification of textual markup systems, uses deterministic regular expressions, i.e. expressions whose Glushkov automaton is deterministic, as a description language for document types. In this paper, we first show that the Glushkov automaton can be constructed in a time quadratic in the size of the expression, and that this is worst-case optimal. For deterministic expressions, our algorithm has even linear run time. This improves on the cubic time methods suggested in the literature (Book 1971; Aho 1986; Berry and Sethi 1986). A major step of the algorithm consists in bringing the expression into what we call star normal form. This concept is also useful for characterizing the relationship between two types of unambiguity that have been studied in the literature. Namely, we show that, modulo a technical condition, an expression is strongly unambiguous (Sippu and Soisalon-Soininen 1988) if and only if it is weakly unambiguous (Book 1971) and in star-normal form. This leads to our third result, a quadratic-time decision algorithm for weak unambiguity, that improves on the biquadratic method introduced by Book (1971). {\textcopyright} 1993.},
	author = {Br{\"{u}}ggemann-Klein, Anne},
	doi = {10.1007/BFb0023820},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Br{\"{u}}ggemann-Klein - 1992 - Regular expressions into finite automata(2).pdf:pdf},
	isbn = {9783540552840},
	issn = {16113349},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	mendeley-groups = {2018 October},
	pages = {87--98},
	title = {{Regular expressions into finite automata}},
	volume = {583 LNCS},
	year = {1992}
}

@article{Berglund2016,
	author = {Berglund, Martin and Merwe, Brink Van Der},
	doi = {10.1016/j.tcs.2016.09.006},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berglund, Merwe - 2016 - On the semantics of regular expression parsing in the wild ✩.pdf:pdf},
	issn = {0304-3975},
	journal = {Theoretical Computer Science},
	keywords = {regular expression matchers},
	mendeley-groups = {2018 April,2018 October},
	pages = {1--14},
	publisher = {Elsevier B.V.},
	title = {{On the semantics of regular expression parsing in the wild}},
	url = {http://dx.doi.org/10.1016/j.tcs.2016.09.006},
	volume = {1},
	year = {2016}
}

@article{Garcia2011,
	abstract = {Several methods have been developed to construct $\lambda$-free automata that represent a regular expression. Among the most widely known are the position automaton (Glushkov), the partial derivatives automaton (Antimirov) and the follow automaton (Ilie and Yu). All these automata can be obtained with quadratic time complexity, thus, the comparison criterion is usually the size of the resulting automaton. The methods that obtain the smallest automata (although, for general expressions, they are not comparable), are the follow and the partial derivatives methods. In this paper, we propose another method to obtain a $\lambda$-free automaton from a regular expression. The number of states of the automata we obtain is bounded above by the size of both the partial derivatives automaton and of the follow automaton. Our algorithm also runs with the same time complexity of these methods. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
	author = {Garc{\'{i}}a, Pedro and L{\'{o}}pez, Dami{\'{a}}n and Ruiz, Jos{\'{e}} and {\'{A}}lvarez, Gloria I.},
	doi = {10.1016/j.tcs.2011.05.058},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Garc{\'{i}}a et al. - 2011 - From regular expressions to smaller NFAs.pdf:pdf},
	isbn = {1251521282},
	issn = {03043975},
	journal = {Theoretical Computer Science},
	keywords = {Finite automata,Position automata quotients,Regular expression},
	mendeley-groups = {2018 October},
	number = {41},
	pages = {5802--5807},
	publisher = {Elsevier B.V.},
	title = {{From regular expressions to smaller NFAs}},
	url = {http://dx.doi.org/10.1016/j.tcs.2011.05.058},
	volume = {412},
	year = {2011}
}

@article{Berry1986,
	abstract = {The main theorem allows an elegant algorithm to be refined into an efficient one. The elegant algorithm for constructing a finite automaton from a regular expression is based on 'derivatives of' regular expressions; the efficient algorithm is based on 'marking of' regular expressions. Derivatives of regular expressions correspond to state transitions in finite automata. When a finite automaton makes a transition under input symbol a, a leading a is stripped from the remaining input. Correspondingly, if the input string is generated by a regular expression E, then the derivative of E by a generates the remaining input after a leading a is stripped. Brzozowski (1964) used derivatives to construct finite automata; the state for expression E has a transition under a to the state for the derivative of E by a. This approach extends to regular expressions with new operators, including intersection and complement; however, explicit computation of derivatives can be expensive. Marking of regular expressions yields an expression with distinct input symbols. Following McNaughton and Yamada (1960), we attach subscripts to each input symbol in an expression; (ab + b)*ba becomes (a1b2+b3)*b4a5. Conceptually, the efficient algorithm constructs an automaton for the marked expression. The marks on the transitions are then erased, resulting in a nondeterministic automaton for the original unmarked expression. This approach works for the usual operations of union, concatenation, and iteration; however, intersection and complement cannot be handled because marking and unmarking do not preserve the languages generated by regular expressions with these operators. {\textcopyright} 1986.},
	author = {Berry, Gerard and Sethi, Ravi},
	doi = {10.1016/0304-3975(86)90088-5},
	file = {:C$\backslash$:/Users/Thales/Dropbox/Dissertation/Qualification/Novos/FROM REGULAR EXPRESSIONS TO DETERMINISTIC AUTOMATA.pdf:pdf},
	issn = {03043975},
	journal = {Theoretical Computer Science},
	mendeley-groups = {2018 April,2018 October},
	number = {C},
	pages = {117--126},
	title = {{From regular expressions to deterministic automata}},
	volume = {48},
	year = {1986}
}

@article{Doczkal2013,
	abstract = {We present a formal constructive theory of regular languages consisting of about 1400 lines of Coq/Ssreflect. As representations we consider regular expressions, deterministic and nondeterministic automata, and Myhill and Nerode partitions. We construct computable functions translating between these representations and show that equivalence of representations is decidable. We also establish the usual closure properties, give a minimization algorithm for DFAs, and prove that minimal DFAs are unique up to state renaming. Our development profits much from Ssreflect's support for finite types and graphs.},
	author = {Doczkal, Christian and Kaiser, Jan Oliver and Smolka, Gert},
	doi = {10.1007/978-3-319-03545-1_6},
	file = {:C$\backslash$:/Users/Thales/Dropbox/Dissertation/Qualification/2018 November/DoczkalEtAl{\_}2013{\_}A-Constructive.pdf:pdf},
	isbn = {9783319035444},
	issn = {03029743},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	keywords = {Coq,Finite automata,Myhill-Nerode,Regular expressions,Regular languages,Ssreflect},
	mendeley-groups = {2018 November},
	pages = {82--97},
	title = {{A constructive theory of regular languages in Coq}},
	volume = {8307 LNCS},
	year = {2013}
}

@article{Groz2017,
	abstract = {A linear time algorithm is presented for testing determinism of a regular expression. It is shown that an input word of length n can be matched against a deterministic regular expression of length m in time O(m+nlog⁡log⁡m). If the deterministic regular expression has bounded depth of alternating union and concatenation operators, then matching can be performed in time O(m+n). These results extend to regular expressions containing numerical occurrence indicators.},
	author = {Groz, B. and Maneth, S.},
	doi = {10.1016/j.jcss.2017.05.013},
	file = {:C$\backslash$:/Users/Thales/Dropbox/Dissertation/Qualification/2018 November/Deterministic Regex.pdf:pdf},
	issn = {10902724},
	journal = {Journal of Computer and System Sciences},
	keywords = {Deterministic regular expression,Matching time complexity,Numerical occurrence indicators,Testing determinism},
	mendeley-groups = {2018 November},
	pages = {372--399},
	publisher = {Elsevier Inc.},
	title = {{Efficient testing and matching of deterministic regular expressions}},
	url = {http://dx.doi.org/10.1016/j.jcss.2017.05.013},
	volume = {89},
	year = {2017}
}

@unpublished{radanne:hal-01788827,
	TITLE = {{Regenerate: A Language Generator for Extended Regular Expressions}},
	AUTHOR = {Radanne, Gabriel and Thiemann, Peter},
	URL = {https://hal.archives-ouvertes.fr/hal-01788827},
	NOTE = {working paper or preprint},
	YEAR = {2018},
	MONTH = May,
	KEYWORDS = {Regular expressions ; parsing ; formal languages ; power series ; Haskell ; OCaml},
	PDF = {https://hal.archives-ouvertes.fr/hal-01788827/file/main.pdf},
	HAL_ID = {hal-01788827},
	HAL_VERSION = {v1},
}

@article{Ilie2003,
	abstract = {We give two new algorithms for constructing small nondeterministic finite automata (NFA) from regular expressions. The first constructs NFAs with e-transitions (eNFA) which are smaller than all the other $\epsilon$NFAs obtained by similar constructions. Their size is at most 3/2|$\alpha$|+5/2, where $\alpha$ is the regular expression. This is very close to optimal since we prove also the lower bound 4/3|$\alpha$|+5/2. The second constructs NFAs. It uses $\epsilon$-elimination in the $\epsilon$NFAs we just introduced and builds a quotient of the well-known position automaton w.r.t, the equivalence given by the follow relation; therefore giving the name of follow automaton. The new automaton uses optimally the information from the positions of a regular expression. We compare the follow automaton with the best constructions to date and show that it has important advantages over those. {\textcopyright} 2003 Elsevier Science (USA). All rights reserved.},
	author = {Ilie, Lucian and Yu, Sheng},
	doi = {10.1016/S0890-5401(03)00090-7},
	file = {:C$\backslash$:/Users/Talles/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ilie, Yu - 2003 - Follow automata.pdf:pdf},
	issn = {08905401},
	journal = {Information and Computation},
	keywords = {Nondeterministic finite automata,Partial derivatives,Quotients,Regular expressions,Right-invariant equivalences,$\epsilon$-Elimination},
	mendeley-groups = {2018 August},
	number = {1},
	pages = {140--162},
	title = {{Follow automata}},
	volume = {186},
	year = {2003}
}


@article{Spivey2012,
	abstract = {Many variations upon the theme of parser combinators have been proposed, too many to list here, but the main idea is simple: A parser for phrases of type $\alpha$ is a function that takes an input string and produces results (x, rest), where x is a value of type $\alpha$, and rest is the remainder of the input after the phrase with value x has been consumed. The results are often arranged into a list, because this allows a parser to signal failure with the empty list of results, an unambiguous success with one result, or multiple possibilities with a longer ‘list of successes'.},
	author = {Spivey, Michael},
	doi = {10.1017/S0956796812000329},
	file = {:C$\backslash$:/Users/Talles/Dropbox/Dissertation/Qualification/2018 September/when-maybe-is-not-good-enough.pdf:pdf},
	issn = {0956-7968},
	journal = {Journal of Functional Programming},
	mendeley-groups = {2018 September},
	number = {06},
	pages = {747--756},
	title = {{When Maybe is not good enough}},
	volume = {22},
	year = {2012}
}
@InProceedings{Sozeau10,
author="Sozeau, Matthieu",
editor="Kaufmann, Matt
and Paulson, Lawrence C.",
title="Equations: A Dependent Pattern-Matching Compiler",
booktitle="Interactive Theorem Proving",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="419--434",
abstract="We present a compiler for definitions made by pattern matching on inductive families in the Coq system. It allows to write structured, recursive dependently-typed functions as a set of equations, automatically find their realization in the core type theory and generate proofs to ease reasoning on them. It provides a complete package to define and reason on functions in the proof assistant, substantially reducing the boilerplate code and proofs one usually has to write, also hiding the intricacies related to the use of dependent types and complex recursion schemes.",
isbn="978-3-642-14052-5"
}
@article{Henglein2011,
author = {Henglein, Fritz and Nielsen, Lasse},
title = {Regular Expression Containment: Coinductive Axiomatization and Computational Interpretation},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/1925844.1926429},
doi = {10.1145/1925844.1926429},
journal = {SIGPLAN Not.},
month = jan,
pages = {385–398},
numpages = {14},
keywords = {computational interpretation, equivalence, coinduction, regular expression, axiomatization, coercion, containment, type} }