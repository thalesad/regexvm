
@inproceedings{Radanne2019,
	author = {Radanne, Gabriel},
	title = {Typed Parsing and Unparsing for Untyped Regular Expression Engines},
	booktitle = {Proceedings of the 2019 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation},
	series = {PEPM 2019},
	year = {2019},
	isbn = {978-1-4503-6226-9},
	location = {Cascais, Portugal},
	pages = {35--46},
	numpages = {12},
	url = {http://doi.acm.org/10.1145/3294032.3294082},
	doi = {10.1145/3294032.3294082},
	acmid = {3294082},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {Functional programming, OCaml, Regular expressions, Static typing, unparsing},
} 

@inproceedings{Gill2007,
	author = {Gill, Andy and Runciman, Colin},
	title = {Haskell Program Coverage},
	booktitle = {Proceedings of the ACM SIGPLAN Workshop on Haskell Workshop},
	series = {Haskell '07},
	year = {2007},
	isbn = {978-1-59593-674-5},
	location = {Freiburg, Germany},
	pages = {1--12},
	numpages = {12},
	url = {http://doi.acm.org/10.1145/1291201.1291203},
	doi = {10.1145/1291201.1291203},
	acmid = {1291203},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {code coverage, haskell, software engineering},
}

@book{Lipovaca2011,
	author = {Lipovaca, Miran},
	title = {Learn You a Haskell for Great Good!: A Beginner's Guide},
	year = {2011},
	isbn = {1593272839, 9781593272838},
	edition = {1st},
	publisher = {No Starch Press},
	address = {San Francisco, CA, USA},
}

@book{Haskell98,
	added-at = {2008-01-15T20:00:13.000+0100},
	biburl = {https://www.bibsonomy.org/bibtex/274578ea79af534c544b545401a50d6e5/thau},
	description = {This report defines the syntax for Haskell programs and an informal abstract semantics for the meaning of such programs.},
	editor = {Jones, Simon Peyton},
	howpublished = {PDF},
	interhash = {bdf24915989dc1673ad9244c4d593b37},
	intrahash = {74578ea79af534c544b545401a50d6e5},
	keywords = {functional-programming haskell},
	month = {September},
	pages = 277,
	publisher = {http://haskell.org/},
	timestamp = {2008-01-15T20:00:13.000+0100},
	title = {Haskell 98 Language and Libraries: The Revised Report},
	type = {Language Definition},
	url = {http://haskell.org/definition/haskell98-report.pdf},
	year = 2002
}

@book{Chlipala13,
	author = {Chlipala, Adam},
	title = {Certified Programming with Dependent Types: A Pragmatic Introduction to the Coq Proof Assistant},
	year = {2013},
	isbn = {0262026651, 9780262026659},
	publisher = {The MIT Press},
} 


@book{Bertot2010,
	author = {Bertot, Yves and Castran, Pierre},
	title = {Interactive Theorem Proving and Program Development: Coq'Art The Calculus of Inductive Constructions},
	year = {2010},
	isbn = {3642058809, 9783642058806},
	edition = {1st},
	publisher = {Springer Publishing Company, Incorporated},
} 

@book{Sorensen2006,
	author = {S{\o}rensen, Morten Heine and Urzyczyn, Pawel},
	title = {Lectures on the Curry-Howard Isomorphism, Volume 149 (Studies in Logic and the Foundations of Mathematics)},
	year = {2006},
	isbn = {0444520775},
	publisher = {Elsevier Science Inc.},
	address = {New York, NY, USA},
}


@article{Thompson1968,
	author = {Thompson, Ken},
	title = {Programming Techniques: Regular Expression Search Algorithm},
	journal = {Commun. ACM},
	issue_date = {June 1968},
	volume = {11},
	number = {6},
	month = jun,
	year = {1968},
	issn = {0001-0782},
	pages = {419--422},
	numpages = {4},
	acmid = {363387},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {match, regular expression, search},
} 

@InProceedings{Lasse2011,
	author="Nielsen, Lasse
	and Henglein, Fritz",
	editor="Dediu, Adrian-Horia
	and Inenaga, Shunsuke
	and Mart{\'i}n-Vide, Carlos",
	title="Bit-coded Regular Expression Parsing",
	booktitle="Language and Automata Theory and Applications",
	year="2011",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="402--413",
	isbn="978-3-642-21254-3"
}

@inproceedings{Claessen2000,
	author = {Claessen, Koen and Hughes, John},
	title = {QuickCheck: A Lightweight Tool for Random Testing of Haskell Programs},
	booktitle = {Proceedings of the Fifth ACM SIGPLAN International Conference on Functional Programming},
	series = {ICFP '00},
	year = {2000},
	isbn = {1-58113-202-6},
	pages = {268--279},
	numpages = {12},
	acmid = {351266},
	publisher = {ACM},
	address = {New York, NY, USA},
} 

@article{Medeiros14,
	author = {Medeiros, S{\'e}rgio and Mascarenhas, Fabio and Ierusalimschy, Roberto},
	title = {From Regexes to Parsing Expression Grammars},
	journal = {Sci. Comput. Program.},
	issue_date = {November, 2014},
	volume = {93},
	month = nov,
	year = {2014},
	issn = {0167-6423},
	pages = {3--18},
	numpages = {16},
	url = {http://dx.doi.org/10.1016/j.scico.2012.11.006},
	doi = {10.1016/j.scico.2012.11.006},
	acmid = {2664811},
	publisher = {Elsevier North-Holland, Inc.},
	address = {Amsterdam, The Netherlands, The Netherlands},
	keywords = {Natural semantics, Parsing expression grammars, Pattern matching, Regexes, Regular expressions},
}

@article{Landin64,
	author = {Landin, P. J.},
	title = {The Mechanical Evaluation of Expressions},
	journal = {The Computer Journal},
	volume = {6},
	number = {4},
	pages = {308-320},
	year = {1964},
	doi = {10.1093/comjnl/6.4.308},
	URL = {http://dx.doi.org/10.1093/comjnl/6.4.308},
	eprint = {/oup/backfile/content_public/journal/comjnl/6/4/10.1093/comjnl/6.4.308/2/6-4-308.pdf}
}
@article{Krivine07,
	author = {Krivine, Jean-Louis},
	title = {A Call-by-name Lambda-calculus Machine},
	journal = {Higher Order Symbol. Comput.},
	issue_date = {September 2007},
	volume = {20},
	number = {3},
	month = sep,
	year = {2007},
	issn = {1388-3690},
	pages = {199--207},
	numpages = {9},
	url = {http://dx.doi.org/10.1007/s10990-007-9018-9},
	doi = {10.1007/s10990-007-9018-9},
	acmid = {1325153},
	publisher = {Kluwer Academic Publishers},
	address = {Hingham, MA, USA},
	keywords = {Control instruction, Curry-Howard correspondence, Lambda-calculus machine},
}

@unpublished{radanne:hal-01788827,
	TITLE = {{Regenerate: A Language Generator for Extended Regular Expressions}},
	AUTHOR = {Radanne, Gabriel and Thiemann, Peter},
	URL = {https://hal.archives-ouvertes.fr/hal-01788827},
	NOTE = {working paper or preprint},
	YEAR = {2018},
	MONTH = May,
	KEYWORDS = {Regular expressions ; parsing ; formal languages ; power series ; Haskell ; OCaml},
	PDF = {https://hal.archives-ouvertes.fr/hal-01788827/file/main.pdf},
	HAL_ID = {hal-01788827},
	HAL_VERSION = {v1},
}

@article{Groz2017,
	abstract = {A linear time algorithm is presented for testing determinism of a regular expression. It is shown that an input word of length n can be matched against a deterministic regular expression of length m in time O(m+nlog⁡log⁡m). If the deterministic regular expression has bounded depth of alternating union and concatenation operators, then matching can be performed in time O(m+n). These results extend to regular expressions containing numerical occurrence indicators.},
	author = {Groz, B. and Maneth, S.},
	doi = {10.1016/j.jcss.2017.05.013},
	file = {:C$\backslash$:/Users/Thales/Dropbox/Dissertation/Qualification/2018 November/Deterministic Regex.pdf:pdf},
	issn = {10902724},
	journal = {Journal of Computer and System Sciences},
	keywords = {Deterministic regular expression,Matching time complexity,Numerical occurrence indicators,Testing determinism},
	mendeley-groups = {2018 November},
	pages = {372--399},
	publisher = {Elsevier Inc.},
	title = {{Efficient testing and matching of deterministic regular expressions}},
	url = {http://dx.doi.org/10.1016/j.jcss.2017.05.013},
	volume = {89},
	year = {2017}
}


@article{Doczkal2013,
	abstract = {We present a formal constructive theory of regular languages consisting of about 1400 lines of Coq/Ssreflect. As representations we consider regular expressions, deterministic and nondeterministic automata, and Myhill and Nerode partitions. We construct computable functions translating between these representations and show that equivalence of representations is decidable. We also establish the usual closure properties, give a minimization algorithm for DFAs, and prove that minimal DFAs are unique up to state renaming. Our development profits much from Ssreflect's support for finite types and graphs.},
	author = {Doczkal, Christian and Kaiser, Jan Oliver and Smolka, Gert},
	doi = {10.1007/978-3-319-03545-1_6},
	file = {:C$\backslash$:/Users/Thales/Dropbox/Dissertation/Qualification/2018 November/DoczkalEtAl{\_}2013{\_}A-Constructive.pdf:pdf},
	isbn = {9783319035444},
	issn = {03029743},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	keywords = {Coq,Finite automata,Myhill-Nerode,Regular expressions,Regular languages,Ssreflect},
	mendeley-groups = {2018 November},
	pages = {82--97},
	title = {{A constructive theory of regular languages in Coq}},
	volume = {8307 LNCS},
	year = {2013}
}


@article{Berry1986,
	abstract = {The main theorem allows an elegant algorithm to be refined into an efficient one. The elegant algorithm for constructing a finite automaton from a regular expression is based on 'derivatives of' regular expressions; the efficient algorithm is based on 'marking of' regular expressions. Derivatives of regular expressions correspond to state transitions in finite automata. When a finite automaton makes a transition under input symbol a, a leading a is stripped from the remaining input. Correspondingly, if the input string is generated by a regular expression E, then the derivative of E by a generates the remaining input after a leading a is stripped. Brzozowski (1964) used derivatives to construct finite automata; the state for expression E has a transition under a to the state for the derivative of E by a. This approach extends to regular expressions with new operators, including intersection and complement; however, explicit computation of derivatives can be expensive. Marking of regular expressions yields an expression with distinct input symbols. Following McNaughton and Yamada (1960), we attach subscripts to each input symbol in an expression; (ab + b)*ba becomes (a1b2+b3)*b4a5. Conceptually, the efficient algorithm constructs an automaton for the marked expression. The marks on the transitions are then erased, resulting in a nondeterministic automaton for the original unmarked expression. This approach works for the usual operations of union, concatenation, and iteration; however, intersection and complement cannot be handled because marking and unmarking do not preserve the languages generated by regular expressions with these operators. {\textcopyright} 1986.},
	author = {Berry, Gerard and Sethi, Ravi},
	doi = {10.1016/0304-3975(86)90088-5},
	file = {:C$\backslash$:/Users/Thales/Dropbox/Dissertation/Qualification/Novos/FROM REGULAR EXPRESSIONS TO DETERMINISTIC AUTOMATA.pdf:pdf},
	issn = {03043975},
	journal = {Theoretical Computer Science},
	mendeley-groups = {2018 April,2018 October},
	number = {C},
	pages = {117--126},
	title = {{From regular expressions to deterministic automata}},
	volume = {48},
	year = {1986}
}


@article{Garcia2011,
	abstract = {Several methods have been developed to construct $\lambda$-free automata that represent a regular expression. Among the most widely known are the position automaton (Glushkov), the partial derivatives automaton (Antimirov) and the follow automaton (Ilie and Yu). All these automata can be obtained with quadratic time complexity, thus, the comparison criterion is usually the size of the resulting automaton. The methods that obtain the smallest automata (although, for general expressions, they are not comparable), are the follow and the partial derivatives methods. In this paper, we propose another method to obtain a $\lambda$-free automaton from a regular expression. The number of states of the automata we obtain is bounded above by the size of both the partial derivatives automaton and of the follow automaton. Our algorithm also runs with the same time complexity of these methods. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
	author = {Garc{\'{i}}a, Pedro and L{\'{o}}pez, Dami{\'{a}}n and Ruiz, Jos{\'{e}} and {\'{A}}lvarez, Gloria I.},
	doi = {10.1016/j.tcs.2011.05.058},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Garc{\'{i}}a et al. - 2011 - From regular expressions to smaller NFAs.pdf:pdf},
	isbn = {1251521282},
	issn = {03043975},
	journal = {Theoretical Computer Science},
	keywords = {Finite automata,Position automata quotients,Regular expression},
	mendeley-groups = {2018 October},
	number = {41},
	pages = {5802--5807},
	publisher = {Elsevier B.V.},
	title = {{From regular expressions to smaller NFAs}},
	url = {http://dx.doi.org/10.1016/j.tcs.2011.05.058},
	volume = {412},
	year = {2011}
}


@article{Berglund2016,
	author = {Berglund, Martin and Merwe, Brink Van Der},
	doi = {10.1016/j.tcs.2016.09.006},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berglund, Merwe - 2016 - On the semantics of regular expression parsing in the wild ✩.pdf:pdf},
	issn = {0304-3975},
	journal = {Theoretical Computer Science},
	keywords = {regular expression matchers},
	mendeley-groups = {2018 April,2018 October},
	pages = {1--14},
	publisher = {Elsevier B.V.},
	title = {{On the semantics of regular expression parsing in the wild}},
	url = {http://dx.doi.org/10.1016/j.tcs.2016.09.006},
	volume = {1},
	year = {2016}
}

@article{Bruggemann-Klein1992,
	abstract = {It is a well-established fact that each regular expression can be transformed into a nondeterministic finite automaton (NFA) with or without $\epsilon$-transitions, and all authors seem to provide their own variant of the construction. Of these, Berry and Sethi (1986) have shown that the construction of an $\epsilon$-free NFA due to Glushkov (1961) is a natural representation of the regular expression because it can be described in terms of Brzozowski derivatives (Brzozowski 1964) of the expression. Moreover, the Glushkov construction also plays a significant role in the document processing area: The SGML standard (ISO 8879 1986), now widely adopted by publishing houses and government agencies for the syntactic specification of textual markup systems, uses deterministic regular expressions, i.e. expressions whose Glushkov automaton is deterministic, as a description language for document types. In this paper, we first show that the Glushkov automaton can be constructed in a time quadratic in the size of the expression, and that this is worst-case optimal. For deterministic expressions, our algorithm has even linear run time. This improves on the cubic time methods suggested in the literature (Book 1971; Aho 1986; Berry and Sethi 1986). A major step of the algorithm consists in bringing the expression into what we call star normal form. This concept is also useful for characterizing the relationship between two types of unambiguity that have been studied in the literature. Namely, we show that, modulo a technical condition, an expression is strongly unambiguous (Sippu and Soisalon-Soininen 1988) if and only if it is weakly unambiguous (Book 1971) and in star-normal form. This leads to our third result, a quadratic-time decision algorithm for weak unambiguity, that improves on the biquadratic method introduced by Book (1971). {\textcopyright} 1993.},
	author = {Br{\"{u}}ggemann-Klein, Anne},
	doi = {10.1007/BFb0023820},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Br{\"{u}}ggemann-Klein - 1992 - Regular expressions into finite automata(2).pdf:pdf},
	isbn = {9783540552840},
	issn = {16113349},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	mendeley-groups = {2018 October},
	pages = {87--98},
	title = {{Regular expressions into finite automata}},
	volume = {583 LNCS},
	year = {1992}
}


@article{Mascarenhas2011,
	archivePrefix = {arXiv},
	arxivId = {arXiv:1210.4992v1},
	author = {Mascarenhas, Fabio and Ierusalimschy, Roberto},
	eprint = {arXiv:1210.4992v1},
	file = {:C$\backslash$:/Users/Thales/Dropbox/Dissertation/Qualification/2018 September/medeiros11regular.pdf:pdf},
	journal = {Brazilian Symposium on Programming Languages},
	keywords = {natural,parsing expression grammars,pattern matching,regular expressions,semantics},
	mendeley-groups = {2018 September},
	title = {{From Regular Expressions to Parsing Expression Grammars}},
	year = {2011}
}


@article{Spivey2012,
	abstract = {Many variations upon the theme of parser combinators have been proposed, too many to list here, but the main idea is simple: A parser for phrases of type $\alpha$ is a function that takes an input string and produces results (x, rest), where x is a value of type $\alpha$, and rest is the remainder of the input after the phrase with value x has been consumed. The results are often arranged into a list, because this allows a parser to signal failure with the empty list of results, an unambiguous success with one result, or multiple possibilities with a longer ‘list of successes'.},
	author = {Spivey, Michael},
	doi = {10.1017/S0956796812000329},
	file = {:C$\backslash$:/Users/Talles/Dropbox/Dissertation/Qualification/2018 September/when-maybe-is-not-good-enough.pdf:pdf},
	issn = {0956-7968},
	journal = {Journal of Functional Programming},
	mendeley-groups = {2018 September},
	number = {06},
	pages = {747--756},
	title = {{When Maybe is not good enough}},
	volume = {22},
	year = {2012}
}

@mastersthesis{Lopes2018,
	abstract = {Parsing is pervasive in computing and fundamental in several software artifacts. This dissertation reports the rst step in our ultimate goal: a formally veri ed toolset for parsing regular and context free languages based on derivatives. Speci cally, we describe the formalization of Brzozowski and Antimirov derivative based algorithms for regular expression parsing, in the dependently typed language Agda. The formalization produces a proof that either an input string matches a given regular expression or that no matching exists. A tool for regular expression based search in the style of the well known GNU grep has been developed using the certi ed algorithms. Practical experiments conducted using this tool are reported.},
	author = {Lopes, Raul Felipe Pimenta},
	file = {:C$\backslash$:/Users/Talles/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Felipe, Lopes - 2018 - Expressions.pdf:pdf},
	year={2018},
	school={Federal University of Ouro Preto},
	title={Certified Derivative-based Parsing of Regular Expressions},
	address={Ouro Preto, MG}
}

@article{Ierusalimschy2009,
	abstract = {Current text pattern-matching tools are based on regular expressions. However, pure regular expressions have proven too weak a formalism for the task: many interesting patterns either are difficult to describe or cannot be described by regular expressions. Moreover, the inherent non- determinism of regular expressions does not fit the need to capture specific parts of a match. Motivated by these reasons, most scripting languages nowadays use pattern-matching tools that extend the original regular-expression formalism with a set of ad-hoc features, such as greedy repetitions, lazy repetitions, possessive repetitions, “longest match rule”, lookahead, etc. These ad-hoc extensions bring their own set of problems, such as lack of a formal foundation and complex implementations. In this paper, we propose the use of Parsing Expression Grammars (PEGs) as a basis for pattern matching. Following this proposal, we present LPEG, a pattern-matching tool based on PEGs for the Lua scripting language. LPEG unifies the ease of use of pattern-matching tools with the full expressive power of PEGs. Because of this expressive power, it can avoid the myriad of ad-hoc constructions present in several current pattern-matching tools. We also present a Parsing Machine that allows a small and efficient implementation of PEGs for pattern matching.},
	author = {Ierusalimschy, Roberto},
	doi = {10.1002/spe.892},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ierusalimschy - 2009 - A text patternmatching tool based on parsing expression grammars.pdf:pdf},
	issn = {00380644},
	journal = {Software - Practice and Experience},
	keywords = {Parsing expression grammars,Pattern matching,Scripting languages},
	title = {{A Text Pattern-Matching Tool based on Parsing Expression Grammars}},
	year = {2009}
}

@article{Cox2009,
	author = {Cox, Russ},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cox - 2009 - Regular Expression Matching the Virtual Machine Approach.pdf:pdf},
	mendeley-groups = {Directly related},
	title = {{Regular Expression Matching: the Virtual Machine Approach}},
	url = {https://swtch.com/{~}rsc/regexp/regexp2.html},
	year = {2009}
}

@article{Fischer2010,
	abstract = {Cody, Hazel, and Theo, two experienced Haskell programmers and an expert in automata theory, develop an elegant Haskell program for matching regular expressions: (i) the program is purely functional; (ii) it is overloaded over arbitrary semirings, which not only allows to solve the ordinary matching problem but also supports other applications like computing leftmost longest matchings or the number of matchings, all with a single algorithm; (iii) it is more powerful than other matchers, as it can be used for parsing every context-free language by taking advantage of laziness.$\backslash$n$\backslash$nThe developed program is based on an old technique to turn regular expressions into finite automata which makes it efficient both in terms of worst-case time and space bounds and actual performance: despite its simplicity, the Haskell implementation can compete with a recently published professional C++ program for the same problem.},
	author = {Fischer, Sebastian and Huch, Frank and Wilke, Thomas},
	doi = {10.1145/1932681.1863594},
	file = {:C$\backslash$:/Users/Thales/Dropbox/Disserta{\c{c}}{\~{a}}o/Qualifica{\c{c}}{\~{a}}o/regexp-play.pdf:pdf},
	isbn = {9781605587943},
	issn = {03621340},
	journal = {ACM SIGPLAN Notices},
	keywords = {a laptop,a whiteboard next to,finite automata,glushkov con-,h azel sitting at,her desk,keyboard,nearby,purely functional programming,regular expressions,struction,the desk,to the left,two office chairs},
	mendeley-groups = {Directly related},
	number = {9},
	pages = {357},
	title = {{A play on regular expressions}},
	url = {papers2://publication/uuid/CE64D2A8-5A9F-444C-A677-EE49DFF386D2{\%}5Cnhttp://portal.acm.org/citation.cfm?doid=1932681.1863594},
	volume = {45},
	year = {2010}
}

@inproceedings{Frisch2004,
	author    = {Alain Frisch and
	Luca Cardelli},
	title     = {Greedy Regular Expression Matching},
	booktitle = {Automata, Languages and Programming: 31st International Colloquium,
	{ICALP} 2004, Turku, Finland, July 12-16, 2004. Proceedings},
	pages     = {618--629},
	year      = {2004},
	crossref  = {DBLP:conf/icalp/2004},
	url       = {https://doi.org/10.1007/978-3-540-27836-8\_53},
	doi       = {10.1007/978-3-540-27836-8\_53},
	timestamp = {Tue, 14 May 2019 10:00:44 +0200},
	biburl    = {https://dblp.org/rec/bib/conf/icalp/FrischC04},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Ribeiro2017,
	author = {Ribeiro, Rodrigo and Bois, Andr{\'{e}} Du},
	doi = {10.1145/3125374.3125381},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ribeiro, Bois - 2017 - Certified Bit-Coded Regular Expression Parsing.pdf:pdf},
	isbn = {9781450353892},
	journal = {Proceedings of the 21st Brazilian Symposium on Programming Languages  - SBLP 2017},
	keywords = {bit-codes,certi ed algorithms,dependent,regular expressions},
	mendeley-groups = {Novos},
	pages = {1--8},
	title = {{Certified Bit-Coded Regular Expression Parsing}},
	url = {http://dl.acm.org/citation.cfm?doid=3125374.3125381},
	year = {2017}
}

@article{Nielsen2011,
	author = {Nielsen, Lasse and Henglein, Fritz},
	doi = {10.1007/978-3-642-21254-3_32},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nielsen, Henglein - 2011 - Bit-coded Regular Expression Parsing.pdf:pdf},
	isbn = {9783642212536},
	issn = {16113349},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	mendeley-groups = {Novos},
	pages = {402--413},
	title = {{Bit-coded Regular Expression Parsing}},
	volume = {6638 LNCS},
	year = {2011}
}

@article{Medeiros2008,
	abstract = {Parsing Expression Grammar (PEG) is a recognition-based foundation for describing syntax that renewed interest in top-down parsing approaches. Generally, the implementation of PEGs is based on a recursive-descent parser, or uses a memoization algorithm.},
	author = {Medeiros, S{\'{e}}rgio and Ierusalimschy, Roberto},
	doi = {10.1145/1408681.1408683},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Medeiros, Ierusalimschy - 2008 - A parsing machine for PEGs.pdf:pdf},
	isbn = {9781605582702},
	journal = {Proceedings of the 2008 symposium on Dynamic languages - DLS '08},
	keywords = {parsing expression grammars,parsing machine,pattern},
	mendeley-groups = {Novos},
	pages = {1--12},
	title = {{A parsing machine for PEGs}},
	url = {http://portal.acm.org/citation.cfm?doid=1408681.1408683},
	year = {2008}
}

@article{Grathwohl2014,
	author = {Grathwohl, Niels Bj{\o}rn Bugge and Henglein, Fritz and Rasmussen, Ulrik Terp},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grathwohl, Henglein, Rasmussen - 2014 - A Crash-Course in Regular Expression Parsing and Regular Expressions as Types.pdf:pdf},
	mendeley-groups = {Novos},
	title = {{A Crash-Course in Regular Expression Parsing and Regular Expressions as Types}},
	year = {2014}
}

@book{Hutton2007,
	abstract = {Haskell is one of the leading languages for teaching functional programming, enabling students to write simpler and cleaner code, and to learn how to},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {Hutton, Graham},
	booktitle = {Solutions},
	doi = {10.1017/S0956796809007151},
	eprint = {arXiv:1011.1669v3},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hutton - 2007 - Programming in Haskell.pdf:pdf},
	isbn = {0521692695},
	issn = {1098-6596},
	mendeley-groups = {Directly related},
	pages = {1--184},
	pmid = {25246403},
	title = {{Programming in Haskell}},
	year = {2007}
}

@unpublished{etheses6011,
	month = {July},
	title = {Semantics, analysis and security of backtracking regular expression matchers},
	school = {University of Birmingham},
	author = {Asiri Rathnayake },
	year = {2015},
	url = {http://etheses.bham.ac.uk/6011/},
	abstract = {Regular expressions are ubiquitous in computer science. Originally defined by Kleene in 1956, they have become a staple of the computer science undergraduate curriculum. Practical applications of regular expressions are numerous, ranging from compiler construction through smart text editors to network intrusion detection systems. Despite having been vigorously studied and formalized in many ways, recent practical implementations of regular expressions have drawn criticism for their use of a non-standard backtracking algorithm. In this research, we investigate the reasons for this deviation and develop a semantics view of regular expressions that formalizes the backtracking paradigm. In the process we discover a novel static analysis capable of detecting exponential runtime vulnerabilities; an extremely undesired reality of backtracking regular expression matchers. }
}

@article{Rathnayake2011,
	abstract = {Many programming languages and tools, ranging from grep to the Java String library, contain regular expression matchers. Rather than first translating a regular expression into a deterministic finite automaton, such implementations typically match the regular expression on the fly. Thus they can be seen as virtual machines interpreting the regular expression much as if it were a program with some non-deterministic constructs such as the Kleene star. We formalize this implementation technique for regular expression matching using operational semantics. Specifically, we derive a series of abstract machines, moving from the abstract definition of matching to increasingly realistic machines. First a continuation is added to the operational semantics to describe what remains to be matched after the current expression. Next, we represent the expression as a data structure using pointers, which enables redundant searches to be eliminated via testing for pointer equality. From there, we arrive both at Thompson's lockstep construction and a machine that performs some operations in parallel, suitable for implementation on a large number of cores, such as a GPU. We formalize the parallel machine using process algebra and report some preliminary experiments with an implementation on a graphics processor using CUDA.},
	archivePrefix = {arXiv},
	arxivId = {1108.3126},
	author = {Rathnayake, Asiri and Thielecke, Hayo},
	doi = {10.4204/EPTCS.62.3},
	eprint = {1108.3126},
	file = {:C$\backslash$:/Users/Thales/Dropbox/Disserta{\c{c}}{\~{a}}o/Qualifica{\c{c}}{\~{a}}o/Novos/Regular Expression Matching and Operactional Semantics.pdf:pdf},
	issn = {2075-2180},
	journal = {Electronic Proceedings in Theoretical Computer Science},
	mendeley-groups = {New Articles},
	number = {Sos},
	pages = {31--45},
	title = {{Regular Expression Matching and Operational Semantics}},
	url = {http://arxiv.org/abs/1108.3126},
	volume = {62},
	year = {2011}
}

@book{Pierce2000,
	abstract = {A type system is a syntactic method for automatically checking the absence of certain erroneous behaviors by classifying program phrases according to the kinds of values they compute. The study of type systems-and of programming languages from a type-theoretic perspective-has important applications in software engineering, language design, high-performance compilers, and security.{\textless}br {\textless}br This text provides a comprehensive introduction both to type systems in computer science and to the basic theory of programming languages. The approach is pragmatic and operational; each new concept is motivated by programming examples and the more theoretical sections are driven by the needs of implementations. Each chapter is accompanied by numerous exercises and solutions, as well as a running implementation, available via the Web. Dependencies between chapters are explicitly identified, allowing readers to choose a variety of paths through the material.{\textless}br {\textless}br The core topics include the untyped lambda-calculus, simple type systems, type reconstruction, universal and existential polymorphism, subtyping, bounded quantification, recursive types, kinds, and type operators. Extended case studies develop a variety of approaches to modeling the features of object-oriented languages.},
	author = {Pierce, Benjamin},
	booktitle = {ACM SIGPLAN Notices},
	doi = {10.1145/360271.360273},
	file = {:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pierce - 2000 - Types and Programming Languages.pdf:pdf;:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pierce - 2000 - Types and Programming Languages(2).pdf:pdf;:C$\backslash$:/Users/Thales/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pierce - 2000 - Types and Programming Languages(3).pdf:pdf;:C$\backslash$:/Users/Thales/Dropbox/Disserta{\c{c}}{\~{a}}o/Qualifica{\c{c}}{\~{a}}o/[Benjamin{\_}C.{\_}Pierce]{\_}Types{\_}and{\_}Programming{\_}Languag(BookSee.org).pdf:pdf},
	isbn = {0262162091},
	issn = {03621340},
	mendeley-groups = {Books},
	number = {8},
	pages = {20--30},
	title = {{Types and Programming Languages}},
	url = {http://portal.acm.org/citation.cfm?doid=360271.360273},
	volume = {35},
	year = {2000}
}
@article{Knuth71,
 author = {Knuth, Donald E.},
 title = {Top-down Syntax Analysis},
 journal = {Acta Inf.},
 issue_date = {June      1971},
 volume = {1},
 number = {2},
 month = jun,
 year = {1971},
 issn = {0001-5903},
 pages = {79--110},
 numpages = {32},
 url = {http://dx.doi.org/10.1007/BF00289517},
 doi = {10.1007/BF00289517},
 acmid = {2698042},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
} 
@inproceedings{Ford04,
 author = {Ford, Bryan},
 title = {Parsing Expression Grammars: A Recognition-based Syntactic Foundation},
 booktitle = {Proceedings of the 31st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
 series = {POPL '04},
 year = {2004},
 isbn = {1-58113-729-X},
 location = {Venice, Italy},
 pages = {111--122},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/964001.964011},
 doi = {10.1145/964001.964011},
 acmid = {964011},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {BNF, GTDPL, TDPL, context-free grammars, lexical analysis, packrat parsing, parsing expression grammars, regular expressions, scannerless parsing, syntactic predicates, unified grammars},
}
@inproceedings{Firsov13,
 author = {Firsov, Denis and Uustalu, Tarmo},
 title = {Certified Parsing of Regular Languages},
 booktitle = {Proceedings of the Third International Conference on Certified Programs and Proofs - Volume 8307},
 year = {2013},
 isbn = {978-3-319-03544-4},
 pages = {98--113},
 numpages = {16},
 url = {http://dx.doi.org/10.1007/978-3-319-03545-1_7},
 doi = {10.1007/978-3-319-03545-1_7},
 acmid = {2695040},
 publisher = {Springer-Verlag New York, Inc.},
 address = {New York, NY, USA},
} 
@InProceedings{Sulzmann14,
author="Sulzmann, Martin
and Lu, Kenny Zhuo Ming",
editor="Codish, Michael
and Sumii, Eijiro",
title="POSIX Regular Expression Parsing with Derivatives",
booktitle="Functional and Logic Programming",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="203--220",
abstract="We adapt the POSIX policy to the setting of regular expression parsing. POSIX favors longest left-most parse trees. Compared to other policies such as greedy left-most, the POSIX policy is more intuitive but much harder to implement. Almost all POSIX implementations are buggy as observed by Kuklewicz. We show how to obtain a POSIX algorithm for the general parsing problem based on Brzozowski's regular expression derivatives. Correctness is fairly straightforward to establish and our benchmark results show that our approach is promising.",
isbn="978-3-319-07151-0"
}
@book{Hopcroft2000,
 author = {Hopcroft, John E. and Motwani, Rajeev and Rotwani and Ullman, Jeffrey D.},
 title = {Introduction to Automata Theory, Languages and Computability},
 year = {2000},
 isbn = {0201441241},
 edition = {2nd},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
} 
@Misc{Grep,
  key =      {Grep},
  title =    {{GNU Grep home page}},
  howpublished = {\verb+https://www.gnu.org/software/grep/+},
}
@inproceedings{Hutton98,
        title = "{Fold and Unfold for Program Semantics}",
        author = "Graham Hutton",
        booktitle = "{Proceedings of the 3rd ACM SIGPLAN International
                Conference on Functional Programming}",
        address = "Baltimore, Maryland",
        month = sep,
        year = 1998}
@inproceedings{Lopes2016,
  author    = {Raul Lopes and Rodrigo Ribeiro and
               Carlos Camar{\~{a}}o},
  title     = {Certified Derivative-Based Parsing of Regular Expressions},
  booktitle = {Programming Languages --- Lecture Notes in Computer Science 9889},
  pages     = {95--109},
  year      = {2016},
  publisher = {Springer}
}

@article{Asperti10,
  author    = {Andrea Asperti and
Claudio Sacerdoti Coen and
Enrico Tassi},
title     = {Regular Expressions, au point},
journal   = {CoRR},
volume    = {abs/1010.2604},
year      = {2010},
url       = {http://arxiv.org/abs/1010.2604},
archivePrefix = {arXiv},
eprint    = {1010.2604},
timestamp = {Mon, 13 Aug 2018 16:48:11 +0200},
biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1010-2604},
bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{Hindley2008,
 author = {Hindley, J. Roger and Seldin, Jonathan P.},
 title = {Lambda-Calculus and Combinators: An Introduction},
 year = {2008},
 isbn = {0521898854, 9780521898850},
 edition = {2},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
}
@InProceedings{Ausaf16,
author="Ausaf, Fahad
and Dyckhoff, Roy
and Urban, Christian",
editor="Blanchette, Jasmin Christian
and Merz, Stephan",
title="POSIX Lexing with Derivatives of Regular Expressions (Proof Pearl)",
booktitle="Interactive Theorem Proving",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="69--86",
abstract="Brzozowski introduced the notion of derivatives for regular expressions. They can be used for a very simple regular expression matching algorithm. Sulzmann and Lu cleverly extended this algorithm in order to deal with POSIX matching, which is the underlying disambiguation strategy for regular expressions needed in lexers. Sulzmann and Lu have made available on-line what they call a ``rigorous proof'' of the correctness of their algorithm w.r.t. their specification; regrettably, it appears to us to have unfillable gaps. In the first part of this paper we give our inductive definition of what a POSIX value is and show (i) that such a value is unique (for given regular expression and string being matched) and (ii) that Sulzmann and Lu's algorithm always generates such a value (provided that the regular expression matches the string). We also prove the correctness of an optimised version of the POSIX matching algorithm. Our definitions and proof are much simpler than those by Sulzmann and Lu and can be easily formalised in Isabelle/HOL. In the second part we analyse the correctness argument by Sulzmann and Lu and explain why the gaps in this argument cannot be filled easily.",
isbn="978-3-319-43144-4"
}

@Article{Dube2000,
	author="Dub{\'e}, Danny
	and Feeley, Marc",
	title="Efficiently building a parse tree from a regular expression",
	journal="Acta Informatica",
	year="2000",
	month="Sep",
	day="01",
	volume="37",
	number="2",
	pages="121--144",
	abstract="We show in this paper that parsing with regular expressions instead of context-free grammars, when it is possible, is desirable. We present efficient algorithms for performing different tasks that concern parsing: producing the external representation and the internal representation of parse trees; producing all possible parse trees or a single one. Each of our algorithms to produce a parse tree from an input string has an optimal time complexity, linear with the length of the string. Moreover, ambiguous regular expressions can be used.",
	issn="1432-0525",
	doi="10.1007/s002360000037",
	url="https://doi.org/10.1007/s002360000037"
}


@article{Ilie2003,
	abstract = {We give two new algorithms for constructing small nondeterministic finite automata (NFA) from regular expressions. The first constructs NFAs with e-transitions (eNFA) which are smaller than all the other $\epsilon$NFAs obtained by similar constructions. Their size is at most 3/2|$\alpha$|+5/2, where $\alpha$ is the regular expression. This is very close to optimal since we prove also the lower bound 4/3|$\alpha$|+5/2. The second constructs NFAs. It uses $\epsilon$-elimination in the $\epsilon$NFAs we just introduced and builds a quotient of the well-known position automaton w.r.t, the equivalence given by the follow relation; therefore giving the name of follow automaton. The new automaton uses optimally the information from the positions of a regular expression. We compare the follow automaton with the best constructions to date and show that it has important advantages over those. {\textcopyright} 2003 Elsevier Science (USA). All rights reserved.},
	author = {Ilie, Lucian and Yu, Sheng},
	doi = {10.1016/S0890-5401(03)00090-7},
	file = {:C$\backslash$:/Users/Talles/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ilie, Yu - 2003 - Follow automata.pdf:pdf},
	issn = {08905401},
	journal = {Information and Computation},
	keywords = {Nondeterministic finite automata,Partial derivatives,Quotients,Regular expressions,Right-invariant equivalences,$\epsilon$-Elimination},
	mendeley-groups = {2018 August},
	number = {1},
	pages = {140--162},
	title = {{Follow automata}},
	volume = {186},
	year = {2003}
}

@book{Aho1986,
	author = {Aho, Alfred V. and Sethi, Ravi and Ullman, Jeffrey D.},
	title = {Compilers: Principles, Techniques, and Tools},
	year = {1986},
	isbn = {0-201-10088-6},
	publisher = {Addison-Wesley Longman Publishing Co., Inc.},
	address = {Boston, MA, USA},
}

@book{Felleisen2009,
	author = {Felleisen, Matthias and Findler, Robert Bruce and Flatt, Matthew},
	title = {Semantics Engineering with PLT Redex},
	year = {2009},
	isbn = {0262062755, 9780262062756},
	edition = {1st},
	publisher = {The MIT Press},
}

@inproceedings{McBride08,
	author    = {Conor McBride},
	title     = {Clowns to the left of me, jokers to the right (pearl): dissecting
	data structures},
	booktitle = {Proceedings of the 35th {ACM} {SIGPLAN-SIGACT} Symposium on Principles
	of Programming Languages, {POPL} 2008, San Francisco, California,
	USA, January 7-12, 2008},
	pages     = {287--295},
	year      = {2008},
	crossref  = {DBLP:conf/popl/2008},
	url       = {http://doi.acm.org/10.1145/1328438.1328474},
	doi       = {10.1145/1328438.1328474},
	timestamp = {Tue, 22 May 2012 15:24:56 +0200},
	biburl    = {https://dblp.org/rec/bib/conf/popl/McBride08},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{AbbottAGM03,
	author    = {Michael Gordon Abbott and
	Thorsten Altenkirch and
	Neil Ghani and
	Conor McBride},
	title     = {Derivatives of Containers},
	booktitle = {Typed Lambda Calculi and Applications, 6th International Conference,
	{TLCA} 2003, Valencia, Spain, June 10-12, 2003, Proceedings.},
	pages     = {16--30},
	year      = {2003},
	crossref  = {DBLP:conf/tlca/2003},
	url       = {https://doi.org/10.1007/3-540-44904-3_2},
	doi       = {10.1007/3-540-44904-3_2},
	timestamp = {Mon, 29 May 2017 16:53:44 +0200},
	biburl    = {https://dblp.org/rec/bib/conf/tlca/AbbottAGM03},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{regexvm-rep,
	author = {Delfino, Thales and Ribeiro, Rodrigo}, 
	title   = {Towards certified virtual machine-based regular expression parsing  --- On-line repository}, 
	howpublished = {https://github.com/thalesad/regexvm},
	year    = {2018}
}

@misc{regex-applicative,
	author = {Cheplyaka, Roman}, 
	title   = {regex-applicative: Regex based parsing with applicative interface  --- On-line repository}, 
	howpublished = {http://hackage.haskell.org/package/regex-applicative},
	year    = {2018}
}

@article{Mcbride2008,
	author = {Mcbride, Conor and Paterson, Ross},
	title = {Applicative Programming with Effects},
	journal = {J. Funct. Program.},
	issue_date = {January 2008},
	volume = {18},
	number = {1},
	month = jan,
	year = {2008},
	issn = {0956-7968},
	pages = {1--13},
	numpages = {13},
	url = {http://dx.doi.org/10.1017/S0956796807006326},
	doi = {10.1017/S0956796807006326},
	acmid = {1348941},
	publisher = {Cambridge University Press},
	address = {New York, NY, USA},
} 

@InProceedings{Kirrage13,
	author="Kirrage, James
	and Rathnayake, Asiri
	and Thielecke, Hayo",
	editor="Lopez, Javier
	and Huang, Xinyi
	and Sandhu, Ravi",
	title="Static Analysis for Regular Expression Denial-of-Service Attacks",
	booktitle="Network and System Security",
	year="2013",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="135--148",
	abstract="Regular expressions are a concise yet expressive language for expressing patterns. For instance, in networked software, they are used for input validation and intrusion detection. Yet some widely deployed regular expression matchers based on backtracking are themselves vulnerable to denial-of-service attacks, since their runtime can be exponential for certain input strings. This paper presents a static analysis for detecting such vulnerable regular expressions. The running time of the analysis compares favourably with tools based on fuzzing, that is, randomly generating inputs and measuring how long matching them takes. Unlike fuzzers, the analysis pinpoints the source of the vulnerability and generates possible malicious inputs for programmers to use in security testing. Moreover, the analysis has a firm theoretical foundation in abstract machines. Testing the analysis on two large repositories of regular expressions shows that the analysis is able to find significant numbers of vulnerable regular expressions in a matter of seconds.",
	isbn="978-3-642-38631-2"
}

@inproceedings{DelfinoRibeiro2018,
	author = {Delfino, Thales Ant\^{o}nio and Ribeiro, Rodrigo},
	title = {Towards Certified Virtual Machine-based Regular Expression Parsing},
	booktitle = {Proceedings of the XXII Brazilian Symposium on Programming Languages},
	series = {SBLP '18},
	year = {2018},
	isbn = {978-1-4503-6480-5},
	location = {Sao Carlos, Brazil},
	pages = {67--74},
	numpages = {8},
	url = {http://doi.acm.org/10.1145/3264637.3264646},
	doi = {10.1145/3264637.3264646},
	acmid = {3264646},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {operational semantics, parsing, regular expressions, virtual machines},
} 